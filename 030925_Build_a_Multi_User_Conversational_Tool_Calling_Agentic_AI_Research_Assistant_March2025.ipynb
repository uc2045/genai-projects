{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/uc2045/genai-projects/blob/master/030925_Build_a_Multi_User_Conversational_Tool_Calling_Agentic_AI_Research_Assistant_March2025.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build a Multi-User Conversational Tool-Calling Agentic AI Research Assistant with LangChain"
      ],
      "metadata": {
        "id": "1kiH8lf1y4sD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This demo will cover building AI Agents with the legacy LangChain `AgentExecutor`. These are fine for getting started, but for working with more advanced agents, LangChain recommends to use LangGraph, which we will cover in the future demos.\n",
        "\n",
        "Agents are systems that use an LLM as a reasoning engine to determine which actions to take and what the inputs to those actions should be. The results of those actions can then be fed back into the agent and it determines whether more actions are needed, or whether it is okay to stop.\n",
        "\n",
        "Here we will build a multi-user Conversational Agent which can refer to previous conversations and give more contextual answers by storing agent messages to a SQL database\n",
        "\n",
        "![](https://i.imgur.com/lHWqaT9.png)\n",
        "\n"
      ],
      "metadata": {
        "id": "NYBpZTjLnEXb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install OpenAI, and LangChain dependencies"
      ],
      "metadata": {
        "id": "L1KvMtf54l0d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain==0.3.19\n",
        "!pip install langchain-openai==0.3.8\n",
        "!pip install langchain-community==0.3.19"
      ],
      "metadata": {
        "id": "2evPp14fy258",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0be7ef03-d73b-43ff-efcd-8b0e01830692"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain==0.3.19 in /usr/local/lib/python3.11/dist-packages (0.3.19)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.35 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.19) (0.3.40)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.19) (0.3.6)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.19) (0.3.11)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.19) (2.10.6)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.19) (2.0.38)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.19) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.19) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.19) (3.11.13)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.19) (9.0.0)\n",
            "Requirement already satisfied: numpy<2,>=1.26.4 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.19) (1.26.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.19) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.19) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.19) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.19) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.19) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.19) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.19) (1.18.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.35->langchain==0.3.19) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.35->langchain==0.3.19) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.35->langchain==0.3.19) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain==0.3.19) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain==0.3.19) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain==0.3.19) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain==0.3.19) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.19) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.19) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain==0.3.19) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain==0.3.19) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain==0.3.19) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain==0.3.19) (2025.1.31)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.3.19) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain==0.3.19) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain==0.3.19) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain==0.3.19) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.35->langchain==0.3.19) (3.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain==0.3.19) (1.3.1)\n",
            "Collecting langchain-openai==0.3.8\n",
            "  Downloading langchain_openai-0.3.8-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting langchain-core<1.0.0,>=0.3.42 (from langchain-openai==0.3.8)\n",
            "  Downloading langchain_core-0.3.43-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.58.1 in /usr/local/lib/python3.11/dist-packages (from langchain-openai==0.3.8) (1.61.1)\n",
            "Collecting tiktoken<1,>=0.7 (from langchain-openai==0.3.8)\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.42->langchain-openai==0.3.8) (0.3.11)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.42->langchain-openai==0.3.8) (9.0.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.42->langchain-openai==0.3.8) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.42->langchain-openai==0.3.8) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.42->langchain-openai==0.3.8) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.42->langchain-openai==0.3.8) (4.12.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.42->langchain-openai==0.3.8) (2.10.6)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai==0.3.8) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai==0.3.8) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai==0.3.8) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai==0.3.8) (0.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai==0.3.8) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai==0.3.8) (4.67.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai==0.3.8) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai==0.3.8) (2.32.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.58.1->langchain-openai==0.3.8) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain-openai==0.3.8) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain-openai==0.3.8) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain-openai==0.3.8) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.42->langchain-openai==0.3.8) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.42->langchain-openai==0.3.8) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.42->langchain-openai==0.3.8) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.42->langchain-openai==0.3.8) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.42->langchain-openai==0.3.8) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.42->langchain-openai==0.3.8) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai==0.3.8) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai==0.3.8) (2.3.0)\n",
            "Downloading langchain_openai-0.3.8-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.4/55.4 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.43-py3-none-any.whl (415 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m415.4/415.4 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken, langchain-core, langchain-openai\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.40\n",
            "    Uninstalling langchain-core-0.3.40:\n",
            "      Successfully uninstalled langchain-core-0.3.40\n",
            "Successfully installed langchain-core-0.3.43 langchain-openai-0.3.8 tiktoken-0.9.0\n",
            "Collecting langchain-community==0.3.19\n",
            "  Downloading langchain_community-0.3.19-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.41 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.3.19) (0.3.43)\n",
            "Collecting langchain<1.0.0,>=0.3.20 (from langchain-community==0.3.19)\n",
            "  Downloading langchain-0.3.20-py3-none-any.whl.metadata (7.7 kB)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.3.19) (2.0.38)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.3.19) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.3.19) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.3.19) (3.11.13)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.3.19) (9.0.0)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community==0.3.19)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community==0.3.19)\n",
            "  Downloading pydantic_settings-2.8.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.3.19) (0.3.11)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community==0.3.19)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.3.19) (1.26.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.19) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.19) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.19) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.19) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.19) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.19) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.19) (1.18.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.19)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.19)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.20->langchain-community==0.3.19) (0.3.6)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.20->langchain-community==0.3.19) (2.10.6)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.41->langchain-community==0.3.19) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.41->langchain-community==0.3.19) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.41->langchain-community==0.3.19) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community==0.3.19) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community==0.3.19) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community==0.3.19) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community==0.3.19) (0.23.0)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community==0.3.19)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community==0.3.19) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community==0.3.19) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community==0.3.19) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community==0.3.19) (2025.1.31)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community==0.3.19) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community==0.3.19) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community==0.3.19) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community==0.3.19) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.41->langchain-community==0.3.19) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.20->langchain-community==0.3.19) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.20->langchain-community==0.3.19) (2.27.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.19)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community==0.3.19) (1.3.1)\n",
            "Downloading langchain_community-0.3.19-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading langchain-0.3.20-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m47.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.8.1-py3-none-any.whl (30 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain, langchain-community\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.19\n",
            "    Uninstalling langchain-0.3.19:\n",
            "      Successfully uninstalled langchain-0.3.19\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-0.3.20 langchain-community-0.3.19 marshmallow-3.26.1 mypy-extensions-1.0.0 pydantic-settings-2.8.1 python-dotenv-1.0.1 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Enter Open AI API Key"
      ],
      "metadata": {
        "id": "H9c37cLnSrbg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from getpass import getpass\n",
        "\n",
        "OPENAI_KEY = getpass('Enter Open AI API Key: ')"
      ],
      "metadata": {
        "id": "cv3JzCEx_PAd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ccab915-d505-48d2-d122-9dd16c878c78"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter Open AI API Key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Enter Tavily Search API Key\n",
        "\n",
        "Get a free API key from [here](https://tavily.com/#api)"
      ],
      "metadata": {
        "id": "ucWRRI3QztL2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TAVILY_API_KEY = getpass('Enter Tavily Search API Key: ')"
      ],
      "metadata": {
        "id": "mK-1WLzOrJdb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f57321b-f0d1-4a5c-950c-2702324ce3ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter Tavily Search API Key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Enter WeatherAPI API Key\n",
        "\n",
        "Get a free API key from [here](https://www.weatherapi.com/signup.aspx)"
      ],
      "metadata": {
        "id": "Ce5arICZEEov"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "WEATHER_API_KEY = getpass('Enter WeatherAPI API Key: ')"
      ],
      "metadata": {
        "id": "XpAMz1XgEEov",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc79cbb4-3341-4025-974b-cbbff43ceb0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter WeatherAPI API Key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup Environment Variables"
      ],
      "metadata": {
        "id": "1T0s0um5Svfa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = OPENAI_KEY\n",
        "os.environ['TAVILY_API_KEY'] = TAVILY_API_KEY"
      ],
      "metadata": {
        "id": "x1YSuHNF_lbh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Tools\n",
        "\n",
        "Here we create two custom tools which are wrappers on top of the [Tavily API](https://tavily.com/#api) and [WeatherAPI](https://www.weatherapi.com/)\n",
        "\n",
        "- Web Search tool with information extraction\n",
        "- Weather tool\n",
        "\n",
        "![](https://i.imgur.com/EnrAbJh.png)"
      ],
      "metadata": {
        "id": "howf-v0ARWbv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.utilities.tavily_search import TavilySearchAPIWrapper\n",
        "from langchain_core.tools import tool\n",
        "import requests\n",
        "\n",
        "tavily_search = TavilySearchAPIWrapper()\n",
        "\n",
        "@tool\n",
        "def search_web_extract_info(query: str) -> list:\n",
        "    \"\"\"Search the web for a query. Userful for general information or general news\"\"\"\n",
        "    results = tavily_search.raw_results(query=query,\n",
        "                                        max_results=8,\n",
        "                                        search_depth='advanced',\n",
        "                                        include_answer=False,\n",
        "                                        include_raw_content=True) # it will also scrape the web pages\n",
        "    docs = results['results']\n",
        "    docs = ['## Title'+'\\n\\n'+doc['title']+'\\n\\n'+'## Content'+'\\n\\n'+doc['raw_content'] for doc in docs]\n",
        "    return docs\n",
        "\n",
        "\n",
        "@tool\n",
        "def get_weather(query: str) -> list:\n",
        "    \"\"\"Search weatherapi to get the current weather.\"\"\"\n",
        "    base_url = \"http://api.weatherapi.com/v1/current.json\"\n",
        "    complete_url = f\"{base_url}?key={WEATHER_API_KEY}&q={query}\"\n",
        "\n",
        "    response = requests.get(complete_url)\n",
        "    data = response.json()\n",
        "    if data.get(\"location\"):\n",
        "        return data\n",
        "    else:\n",
        "        return \"Weather Data Not Found\""
      ],
      "metadata": {
        "id": "Ue8xgu9WpuPi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build and Test AI Agent\n",
        "\n",
        "Now that we have defined the tools and the LLM, we can create the agent. We will be using a tool calling agent to bind the tools to the agent with a prompt. We will also add in the capability to store historical conversations as memory"
      ],
      "metadata": {
        "id": "c7kvwG3SmREW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "\n",
        "SYS_PROMPT = \"\"\"Act as a helpful assistant.\n",
        "                You run in a loop of Thought, Action, PAUSE, Observation.\n",
        "                At the end of the loop, you output an Answer.\n",
        "                Use Thought to describe your thoughts about the question you have been asked.\n",
        "                Use Action to run one of the actions available to you - then return PAUSE.\n",
        "                Observation will be the result of running those actions.\n",
        "                Repeat till you get to the answer for the given user query.\n",
        "\n",
        "                Use the following workflow format:\n",
        "                  Question: the input task you must solve\n",
        "                  Thought: you should always think about what to do\n",
        "                  Action: the action to take which can be any of the following:\n",
        "                            - break it into smaller steps if needed\n",
        "                            - see if you can answer the given task with your trained knowledge\n",
        "                            - call the most relevant tools at your disposal mentioned below in case you need more information\n",
        "                  Action Input: the input to the action\n",
        "                  Observation: the result of the action\n",
        "                  ... (this Thought/Action/Action Input/Observation can repeat N times)\n",
        "                  Thought: I now know the final answer\n",
        "                  Final Answer: the final answer to the original input question\n",
        "\n",
        "                Tools at your disposal to perform tasks as needed:\n",
        "                  - get_weather: whenever user asks get the weather of a place.\n",
        "                  - search_web_extract_info: whenever user asks for specific information or if you don't know the answer.\n",
        "             \"\"\"\n",
        "\n",
        "prompt_template = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", SYS_PROMPT),\n",
        "        MessagesPlaceholder(variable_name=\"history\", optional=True),\n",
        "        (\"human\", \"{query}\"),\n",
        "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "prompt_template.messages"
      ],
      "metadata": {
        "id": "grNq1I6_5dxC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1612ec32-b05c-496f-dca8-e2fdef8bba57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template=\"Act as a helpful assistant.\\n                You run in a loop of Thought, Action, PAUSE, Observation.\\n                At the end of the loop, you output an Answer.\\n                Use Thought to describe your thoughts about the question you have been asked.\\n                Use Action to run one of the actions available to you - then return PAUSE.\\n                Observation will be the result of running those actions.\\n                Repeat till you get to the answer for the given user query.\\n\\n                Use the following workflow format:\\n                  Question: the input task you must solve\\n                  Thought: you should always think about what to do\\n                  Action: the action to take which can be any of the following:\\n                            - break it into smaller steps if needed\\n                            - see if you can answer the given task with your trained knowledge\\n                            - call the most relevant tools at your disposal mentioned below in case you need more information\\n                  Action Input: the input to the action\\n                  Observation: the result of the action\\n                  ... (this Thought/Action/Action Input/Observation can repeat N times)\\n                  Thought: I now know the final answer\\n                  Final Answer: the final answer to the original input question\\n\\n                Tools at your disposal to perform tasks as needed:\\n                  - get_weather: whenever user asks get the weather of a place.\\n                  - search_web_extract_info: whenever user asks for specific information or if you don't know the answer.\\n             \"), additional_kwargs={}),\n",
              " MessagesPlaceholder(variable_name='history', optional=True),\n",
              " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['query'], input_types={}, partial_variables={}, template='{query}'), additional_kwargs={}),\n",
              " MessagesPlaceholder(variable_name='agent_scratchpad')]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we can initalize the agent with the LLM, the prompt, and the tools.\n",
        "\n",
        "The agent is responsible for taking in input and deciding what actions to take.\n",
        "\n",
        "REMEMBER the Agent does not execute those actions - that is done by the AgentExecutor\n",
        "\n",
        "Note that we are passing in the model `chatgpt`, not `chatgpt_with_tools`.\n",
        "\n",
        "That is because `create_tool_calling_agent` will call `.bind_tools` for us under the hood.\n",
        "\n",
        "This should ideally be used with an LLM which supports tool \\ function calling"
      ],
      "metadata": {
        "id": "jlJwVepDmsZw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import create_tool_calling_agent\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "chatgpt = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
        "tools = [search_web_extract_info, get_weather]\n",
        "agent = create_tool_calling_agent(chatgpt, tools, prompt_template)"
      ],
      "metadata": {
        "id": "u4NMA82HpueH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we combine the `agent` (the brains) with the `tools` inside the `AgentExecutor` (which will repeatedly call the agent and execute tools)."
      ],
      "metadata": {
        "id": "TiL70NCrmkkW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import AgentExecutor\n",
        "\n",
        "agent_executor = AgentExecutor(agent=agent,\n",
        "                               tools=tools,\n",
        "                               early_stopping_method='force',\n",
        "                               max_iterations=10)"
      ],
      "metadata": {
        "id": "vAuGe5G5pugJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"\"\"Summarize the key points discussed in Nvidia's Q4 2024 earnings call\"\"\"\n",
        "response = chatgpt.invoke(query)\n",
        "print(response.content)"
      ],
      "metadata": {
        "id": "OXqgT0Yth892",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a89145c-f602-4c06-871e-a4a757417161"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "As of my last update, Nvidia's Q4 2024 earnings call has not occurred. However, I can provide a general idea of what typically happens during such calls. In an earnings call, Nvidia's executives would likely discuss:\n",
            "\n",
            "1. **Financial Performance**: Key financial metrics such as revenue, net income, earnings per share, and operating margins. They might compare these figures to previous quarters and the same quarter in the prior year.\n",
            "\n",
            "2. **Segment Performance**: Insights into how different business segments performed, such as gaming, data center, professional visualization, and automotive.\n",
            "\n",
            "3. **Market Trends**: Discussion on trends affecting Nvidia's business, such as demand for GPUs, developments in AI and machine learning, and the impact of cryptocurrency mining on GPU sales.\n",
            "\n",
            "4. **Product Updates**: Information on new product launches, updates to existing products, and future product roadmaps.\n",
            "\n",
            "5. **Strategic Initiatives**: Updates on strategic partnerships, acquisitions, or investments that could impact future growth.\n",
            "\n",
            "6. **Guidance**: Forward-looking statements regarding expectations for the next quarter or fiscal year, including revenue and margin forecasts.\n",
            "\n",
            "7. **Q&A Session**: Responses to questions from analysts and investors, which can provide additional insights into the company's strategy and outlook.\n",
            "\n",
            "For the most accurate and up-to-date information, you would need to refer to the official transcript or summary of Nvidia's Q4 2024 earnings call once it is available.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"\"\"Summarize the key points discussed in Nvidia's Q4 2024 earnings call\"\"\"\n",
        "response = agent_executor.invoke({\"query\": query})"
      ],
      "metadata": {
        "id": "07nRAXEwY7Ea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response"
      ],
      "metadata": {
        "id": "ne8x7JqGPMmf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29846a06-10ab-4722-aac1-d80b8d1d9589"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'query': \"Summarize the key points discussed in Nvidia's Q4 2024 earnings call\",\n",
              " 'output': \"Nvidia's Q4 2024 earnings call highlighted several key points:\\n\\n1. **Financial Performance**: Nvidia reported a record quarterly revenue of $22.1 billion, marking a 22% increase from the previous quarter and a 265% rise from the same period a year ago. The earnings per share (EPS) also saw significant growth, with GAAP EPS at $4.93 and Non-GAAP EPS at $5.16.\\n\\n2. **Data Center Growth**: The data center segment was a major contributor, with revenue reaching $18.4 billion, up 27% sequentially and 409% year-over-year. This growth was driven by the demand for AI inference and the transition to accelerated computing.\\n\\n3. **AI and Accelerated Computing**: Nvidia emphasized the growing demand for AI and accelerated computing, which are becoming central to their strategy. The company is focusing on AI inference, which contributed significantly to the data center revenue.\\n\\n4. **Product and Market Expansion**: Nvidia is expanding its product offerings and market reach, with strategic initiatives in AI and partnerships with major cloud service providers. Despite regulatory challenges in China, Nvidia is adapting by offering alternative products.\\n\\n5. **Future Outlook**: Nvidia provided strong guidance for the next quarter, expecting continued growth driven by AI and accelerated computing. The company is optimistic about its future prospects, supported by its strategic focus and partnerships.\\n\\nOverall, Nvidia's Q4 2024 earnings call underscored its strong financial performance, strategic focus on AI and accelerated computing, and positive outlook for future growth.\"}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Markdown\n",
        "\n",
        "display(Markdown(response['output']))"
      ],
      "metadata": {
        "id": "H2_MM2jrPRya",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "outputId": "f859457a-89aa-4e3f-a056-92090667aaca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Nvidia's Q4 2024 earnings call highlighted several key points:\n\n1. **Financial Performance**: Nvidia reported a record quarterly revenue of $22.1 billion, marking a 22% increase from the previous quarter and a 265% rise from the same period a year ago. The earnings per share (EPS) also saw significant growth, with GAAP EPS at $4.93 and Non-GAAP EPS at $5.16.\n\n2. **Data Center Growth**: The data center segment was a major contributor, with revenue reaching $18.4 billion, up 27% sequentially and 409% year-over-year. This growth was driven by the demand for AI inference and the transition to accelerated computing.\n\n3. **AI and Accelerated Computing**: Nvidia emphasized the growing demand for AI and accelerated computing, which are becoming central to their strategy. The company is focusing on AI inference, which contributed significantly to the data center revenue.\n\n4. **Product and Market Expansion**: Nvidia is expanding its product offerings and market reach, with strategic initiatives in AI and partnerships with major cloud service providers. Despite regulatory challenges in China, Nvidia is adapting by offering alternative products.\n\n5. **Future Outlook**: Nvidia provided strong guidance for the next quarter, expecting continued growth driven by AI and accelerated computing. The company is optimistic about its future prospects, supported by its strategic focus and partnerships.\n\nOverall, Nvidia's Q4 2024 earnings call underscored its strong financial performance, strategic focus on AI and accelerated computing, and positive outlook for future growth."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"\"\"Summarize the key points discussed in Intel's Q4 2024 earnings call\"\"\"\n",
        "response = agent_executor.invoke({\"query\": query})\n",
        "display(Markdown(response['output']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "riHUt00KE_3q",
        "outputId": "4e98aef4-f166-4227-d3ff-6ecd573768be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Intel's Q4 2024 earnings call highlighted several key points:\n\n1. **Financial Performance**: Intel reported Q4 revenue of $14.3 billion, surpassing guidance and showing a 7% sequential increase. The non-GAAP gross margin was 42.1%, and earnings per share (EPS) were $0.13, slightly above the guidance of $0.12. However, the full-year 2024 revenue was $53.1 billion, a 2.1% decline year-over-year, with a full-year EPS of minus $0.13.\n\n2. **Segment Performance**: The Client Computing Group (CCG) generated $8.02 billion in revenue, down 9% year-over-year. The Data Center and AI (DCAI) segment reported $3.39 billion in revenue, a 3% decline. The Network and Edge (NEX) unit saw a 10% increase in revenue to $1.62 billion.\n\n3. **Strategic Initiatives**: Intel is focusing on strengthening its product portfolio and process roadmap. The company plans to launch Panther Lake, its lead product on the Intel 18A process technology, in the second half of 2025. Intel is also working on Jaguar Shores to address the AI data center market more broadly.\n\n4. **Challenges and Outlook**: Intel faces increased competition, particularly in the AI PC category, and is not yet significantly participating in the cloud-based AI data center market. The company expects Q1 2025 revenue to be between $11.7 billion and $12.7 billion, with a breakeven EPS on a non-GAAP basis.\n\n5. **Operational Changes**: Intel is implementing a cost reduction plan and restructuring its business to improve efficiency and profitability. The company is also exploring the establishment of Intel Foundry as an independent subsidiary to enhance governance and operational separation.\n\n6. **Leadership Transition**: Intel appointed two interim co-CEOs, Michelle Johnston Holthaus and David Zinsner, following the departure of former CEO Pat Gelsinger. The search for a permanent CEO is ongoing.\n\n7. **Government Support**: Intel finalized a $7.86 billion U.S. government grant to support manufacturing, reflecting its strategic importance in domestic semiconductor production.\n\nOverall, Intel is navigating market challenges while focusing on innovation and operational efficiency to enhance its competitive position and create shareholder value."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"\"\"which company's future outlook looks to be better?\n",
        "        \"\"\"\n",
        "response = agent_executor.invoke({\"query\": query})\n",
        "display(Markdown(response['output']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "id": "GfBHtCzJFKdb",
        "outputId": "7068c355-9b33-4e2d-dcd1-51da789a3a60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "To provide an accurate assessment of a company's future outlook, I would need to know which specific companies you are interested in comparing. Please provide the names of the companies you would like to evaluate."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"\"\"Tell me about the weather in Zurich, show detailed statistics\n",
        "        \"\"\"\n",
        "response = agent_executor.invoke({\"query\": query})\n",
        "display(Markdown(response['output']))"
      ],
      "metadata": {
        "id": "oPQ9BrMQlBL5",
        "outputId": "f006321e-6d4c-4c35-db04-5f60c848840d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The current weather in Zurich, Switzerland is as follows:\n\n- **Temperature**: 16.4°C (61.5°F)\n- **Condition**: Sunny\n- **Wind**: 4.3 mph (6.8 kph) from the NE\n- **Pressure**: 1010.0 mb (29.83 in)\n- **Precipitation**: 0.0 mm (0.0 in)\n- **Humidity**: 27%\n- **Cloud Cover**: 0%\n- **Feels Like**: 16.4°C (61.5°F)\n- **Wind Chill**: 12.8°C (55.1°F)\n- **Heat Index**: 13.1°C (55.5°F)\n- **Dew Point**: 3.1°C (37.6°F)\n- **Visibility**: 10.0 km (6.0 miles)\n- **UV Index**: 0.3\n- **Wind Gusts**: 6.4 mph (10.3 kph)\n\nThe weather is currently sunny with no cloud cover, and the conditions are quite pleasant with a light breeze."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The agent is doing pretty well but unfortunately it doesn't remember conversations. We will use some user-session based memory to store this and dive deeper into this in the next video."
      ],
      "metadata": {
        "id": "DQQAx3B7xrl-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build and Test Multi-User Conversational AI Agent\n",
        "\n",
        "We will now use `SQLChatMessageHistory` which we learnt in the previous module to store separate conversation histories per user or session.\n",
        "\n",
        "This will help us build a conversational Agentic Chatbot which will be accessed by many users at the same time"
      ],
      "metadata": {
        "id": "Cw9mxPskx734"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# removes the memory database file - usually not needed\n",
        "# you can run this only when you want to remove ALL conversation histories\n",
        "# ok if you get rm: cannot remove 'memory.db': No such file or directory  because initially no memory exists\n",
        "!rm memory.db"
      ],
      "metadata": {
        "id": "EUG09xD5zd2N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75a0157b-f137-4ad9-dc54-ed9d94cdb956"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'memory.db': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.chat_message_histories import SQLChatMessageHistory\n",
        "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
        "\n",
        "# used to retrieve conversation history from database\n",
        "# based on a specific user or session ID\n",
        "def get_session_history_db(session_id):\n",
        "    return SQLChatMessageHistory(session_id, \"sqlite:///memory.db\")\n",
        "\n",
        "# create a conversation chain + agent which can load memory based on specific user or session id\n",
        "agentic_chatbot = RunnableWithMessageHistory(\n",
        "    agent_executor,\n",
        "    get_session_history_db,\n",
        "    input_messages_key=\"query\",\n",
        "    history_messages_key=\"history\",\n",
        ")\n",
        "\n",
        "# function to call the agent show results per user session\n",
        "from IPython.display import display, Markdown\n",
        "def chat_with_agent(prompt: str, session_id: str):\n",
        "    response = agentic_chatbot.invoke({\"query\": prompt},\n",
        "                                      {'configurable': { 'session_id': session_id}})\n",
        "    display(Markdown(response['output']))"
      ],
      "metadata": {
        "id": "_XSzUrlyZyFF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's now simulate User 1 using the agent"
      ],
      "metadata": {
        "id": "vYTNL_iJ6ibC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_id = 'john001'\n",
        "prompt = \"Summarize the key points discussed in Nvidia's Q4 2024 earnings call\"\n",
        "chat_with_agent(prompt, user_id)"
      ],
      "metadata": {
        "id": "irMU68Ds0NTm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "outputId": "4963b38e-2ccb-4e3a-d829-24cdddf37d18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/langchain_core/runnables/history.py:606: LangChainDeprecationWarning: `connection_string` was deprecated in LangChain 0.2.2 and will be removed in 1.0. Use connection instead.\n",
            "  message_history = self.get_session_history(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Nvidia's Q4 2024 earnings call highlighted several key points:\n\n1. **Financial Performance**: Nvidia reported a record quarterly revenue of $22.1 billion, marking a 22% increase from the previous quarter and a 265% rise from the same period a year ago. The earnings per share (EPS) also saw significant growth, with GAAP EPS at $4.93 and Non-GAAP EPS at $5.16.\n\n2. **Data Center Growth**: The data center segment was a major contributor, with revenue reaching $18.4 billion, up 27% sequentially and 409% year-over-year. This growth was driven by the demand for AI inference and the transition to accelerated computing.\n\n3. **AI and Accelerated Computing**: Nvidia emphasized the surging demand for accelerated computing and generative AI across various industries. The company is focusing on AI inference, which contributed to about 40% of the data center's revenue.\n\n4. **Strategic Initiatives**: Nvidia is expanding its strategic collaborations, including partnerships with Google and Amazon Web Services, to enhance its AI platforms. The company is also addressing regulatory challenges in China by offering alternative products.\n\n5. **Future Outlook**: Nvidia provided a strong outlook for the next quarter, expecting revenue to be around $24 billion. The company is optimistic about its growth trajectory, driven by its focus on AI and accelerated computing.\n\n6. **Market Sentiment**: Following the earnings announcement, Nvidia's stock saw a positive reaction, reflecting investor confidence in the company's strategic direction and growth potential.\n\nOverall, Nvidia's Q4 2024 earnings call underscored its strong financial performance, strategic focus on AI and accelerated computing, and positive market sentiment."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"What about Intel?\"\n",
        "chat_with_agent(prompt, user_id)"
      ],
      "metadata": {
        "id": "XT4vtvku0TBW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "outputId": "e4fd29ef-310b-400d-b6b5-c11ade5a7e23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Intel's Q4 2024 earnings call highlighted several key points:\n\n1. **Financial Performance**: Intel reported Q4 revenue of $14.3 billion, which was a 7% sequential increase but a 7% year-over-year decline. The earnings per share (EPS) was $0.13, slightly above the guidance of $0.12. The full-year 2024 revenue was $53.1 billion, down 2.1% from the previous year.\n\n2. **Segment Performance**: The Client Computing Group (CCG) generated $8.02 billion in revenue, down 9% year-over-year. The Data Center and AI segment reported $3.39 billion in revenue, a 3% decline. The Network and Edge unit saw a 10% increase in revenue to $1.62 billion.\n\n3. **Challenges and Strategy**: Intel is facing increased competition, particularly in the AI data center market, and is not yet participating meaningfully in the cloud-based AI data center market. The company is focusing on product innovation and partnerships to improve its market position.\n\n4. **Intel Foundry Services**: Intel Foundry reported $4.5 billion in revenue, with a significant operating loss. The company aims to achieve breakeven operating income for Intel Foundry by the end of 2027.\n\n5. **Future Outlook**: Intel provided a Q1 2025 revenue guidance of $11.7 billion to $12.7 billion, with a breakeven EPS. The company expects gross margins to improve throughout the year, driven by a mix shift to EUV wafers and growth in advanced packaging.\n\n6. **Strategic Initiatives**: Intel is focusing on its 18A process technology, with plans for volume chip production in the second half of 2025. The company is also working on restructuring its business to improve efficiency and profitability.\n\nOverall, Intel's Q4 2024 earnings call reflected a challenging environment with a focus on strategic initiatives to improve competitiveness and financial performance."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Which company seems to be doing better?\"\n",
        "chat_with_agent(prompt, user_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "u-sz15g8YGNA",
        "outputId": "3d40196e-e656-44e2-e8de-baa70b99e57b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Based on the summaries of the Q4 2024 earnings calls for both Nvidia and Intel, Nvidia appears to be performing better than Intel. Here are some key points that highlight Nvidia's stronger position:\n\n1. **Revenue Growth**: Nvidia reported a record quarterly revenue of $22.1 billion, with a significant year-over-year increase of 265%. In contrast, Intel's revenue for the same period was $14.3 billion, which represented a year-over-year decline of 7%.\n\n2. **Profitability**: Nvidia's earnings per share (EPS) showed substantial growth, with both GAAP and Non-GAAP EPS significantly higher than the previous year. Intel's EPS was slightly above guidance but did not show the same level of growth as Nvidia.\n\n3. **Market Demand**: Nvidia is benefiting from strong demand in the AI and accelerated computing sectors, particularly in data centers. This demand is driving significant growth in their data center segment. Intel, on the other hand, is facing challenges in the AI data center market and is not yet participating meaningfully in this area.\n\n4. **Future Outlook**: Nvidia provided a strong revenue outlook for the next quarter, expecting around $24 billion, indicating continued growth momentum. Intel's guidance for the next quarter shows a more modest revenue range and a breakeven EPS, suggesting a more cautious outlook.\n\n5. **Market Sentiment**: Nvidia's stock saw a positive reaction following the earnings announcement, reflecting investor confidence in its strategic direction. Intel's performance and outlook appear to be more conservative, with ongoing challenges in certain segments.\n\nOverall, Nvidia's strong financial performance, growth in key market segments, and positive future outlook suggest that it is currently doing better than Intel."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's now simulate User 2 using the agent"
      ],
      "metadata": {
        "id": "B4zIlISy6m-x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_id = 'bond007'\n",
        "prompt = \"how is the weather in Bangalore today? Show detailed statistics\"\n",
        "chat_with_agent(prompt, user_id)"
      ],
      "metadata": {
        "id": "ta1RUF_81RxX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "outputId": "3c4d25ce-e779-4e9e-db43-cfbadb9b79c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The weather in Bangalore today is sunny with the following detailed statistics:\n\n- **Temperature**: 33.2°C (91.8°F)\n- **Feels Like**: 31.1°C (87.9°F)\n- **Wind**: 8.7 mph (14.0 kph) from the NE\n- **Wind Gusts**: Up to 10.0 mph (16.2 kph)\n- **Humidity**: 20%\n- **Pressure**: 1011.0 mb (29.85 in)\n- **Precipitation**: 0.0 mm (0.0 in)\n- **Cloud Cover**: 0% (Clear skies)\n- **Visibility**: 6.0 km (3.0 miles)\n- **UV Index**: 1.7\n- **Dew Point**: -2.3°C (27.9°F)\n\nThe weather is clear and sunny, making it a good day for outdoor activities."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_id = 'bond007'\n",
        "prompt = \"what about Dubai?\"\n",
        "chat_with_agent(prompt, user_id)"
      ],
      "metadata": {
        "id": "vfn_Wxxg42rZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "outputId": "e542cfde-6723-4ab3-98a7-6c0948dca14d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The weather in Dubai today is sunny with the following detailed statistics:\n\n- **Temperature**: 37.1°C (98.8°F)\n- **Feels Like**: 40.1°C (104.2°F)\n- **Wind**: 7.4 mph (11.9 kph) from the SW\n- **Wind Gusts**: Up to 15.5 mph (24.9 kph)\n- **Humidity**: 9%\n- **Pressure**: 1008.0 mb (29.77 in)\n- **Precipitation**: 0.0 mm (0.0 in)\n- **Cloud Cover**: 0% (Clear skies)\n- **Visibility**: 10.0 km (6.0 miles)\n- **UV Index**: 6.4\n- **Dew Point**: 12.4°C (54.4°F)\n\nThe weather is hot and sunny, typical for Dubai, so it's advisable to stay hydrated and use sun protection if you're outdoors."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_id = 'bond007'\n",
        "prompt = \"which city is hotter?\"\n",
        "chat_with_agent(prompt, user_id)"
      ],
      "metadata": {
        "id": "I7jjxtmz6Qzi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "outputId": "136b5113-93c0-48ba-de74-2852d569d411"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Dubai is hotter than Bangalore today. The temperature in Dubai is 37.1°C (98.8°F), while in Bangalore, it is 33.2°C (91.8°F)."
          },
          "metadata": {}
        }
      ]
    }
  ]
}