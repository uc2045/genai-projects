{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f73178061a614878a24c8f42946ef0f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7ce1c6ea73764acea5bcd6d4d1102326",
              "IPY_MODEL_82670de5446345928b5c831406bd41e1",
              "IPY_MODEL_24534a1566a547428d20cad9b96722e4"
            ],
            "layout": "IPY_MODEL_de4f934c4ae44c1abe845b3c200a57fb"
          }
        },
        "7ce1c6ea73764acea5bcd6d4d1102326": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_363f83b8faaf4f48a76fa45e7800ca7b",
            "placeholder": "​",
            "style": "IPY_MODEL_464dbd5933b54a898d63d5843aeedaa8",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "82670de5446345928b5c831406bd41e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b00ea2688de48028f1346de11a73cfc",
            "max": 1460,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fdae9037908d4bf5b937a7a147e6e092",
            "value": 1460
          }
        },
        "24534a1566a547428d20cad9b96722e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_842a3200dc1248d9b4725b8f1e07331e",
            "placeholder": "​",
            "style": "IPY_MODEL_46948329be9b44feb201005e857aeb1e",
            "value": " 1.46k/1.46k [00:00&lt;00:00, 80.8kB/s]"
          }
        },
        "de4f934c4ae44c1abe845b3c200a57fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "363f83b8faaf4f48a76fa45e7800ca7b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "464dbd5933b54a898d63d5843aeedaa8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3b00ea2688de48028f1346de11a73cfc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fdae9037908d4bf5b937a7a147e6e092": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "842a3200dc1248d9b4725b8f1e07331e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46948329be9b44feb201005e857aeb1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3b3818e6a4f24e88bf6fdeaa285437ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_48e6567719574bc7a44c6e6849cbc523",
              "IPY_MODEL_5e7813887d644e0a99a976f75674355a",
              "IPY_MODEL_d56eec56e62d422ca82bc734bd9c01a6"
            ],
            "layout": "IPY_MODEL_e042b8a8cc14493f9a65f509634394aa"
          }
        },
        "48e6567719574bc7a44c6e6849cbc523": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9952412c6424413788f44b92c11438c1",
            "placeholder": "​",
            "style": "IPY_MODEL_12e0f036b22f4789acdd758a87e714d9",
            "value": "tokenizer.model: 100%"
          }
        },
        "5e7813887d644e0a99a976f75674355a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a5fd596303e34733925477a3ce8eaccf",
            "max": 493443,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fa01f4d390634438a05ba651dba65c51",
            "value": 493443
          }
        },
        "d56eec56e62d422ca82bc734bd9c01a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f663e5c120d445689b6621004dcb955b",
            "placeholder": "​",
            "style": "IPY_MODEL_d2a24d37ceca4c4db172cd619c5d905f",
            "value": " 493k/493k [00:00&lt;00:00, 4.50MB/s]"
          }
        },
        "e042b8a8cc14493f9a65f509634394aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9952412c6424413788f44b92c11438c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12e0f036b22f4789acdd758a87e714d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a5fd596303e34733925477a3ce8eaccf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa01f4d390634438a05ba651dba65c51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f663e5c120d445689b6621004dcb955b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2a24d37ceca4c4db172cd619c5d905f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "382ddd827ee044dda40113f69883091d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9ca7ffb301934499a8737b1162f6b316",
              "IPY_MODEL_b4bb1155db2f4224899f12da88dccddf",
              "IPY_MODEL_dc9b79e653c14a33b695a909f143187d"
            ],
            "layout": "IPY_MODEL_f71c90a688f547509f0930a238bf4d71"
          }
        },
        "9ca7ffb301934499a8737b1162f6b316": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13b81204215241fbafa8559733743cfa",
            "placeholder": "​",
            "style": "IPY_MODEL_6a84515579394b57a20ad00596198f22",
            "value": "tokenizer.json: 100%"
          }
        },
        "b4bb1155db2f4224899f12da88dccddf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_51998b3fba3e49d5a1d29a7b3cb2d206",
            "max": 1795303,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b7cc4d6052a240b49df4e2cabf57350b",
            "value": 1795303
          }
        },
        "dc9b79e653c14a33b695a909f143187d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c437eedd39f64e5b9e07d8b9df0778e7",
            "placeholder": "​",
            "style": "IPY_MODEL_4401d3ed94aa47daa180a939f3f2df8f",
            "value": " 1.80M/1.80M [00:00&lt;00:00, 13.8MB/s]"
          }
        },
        "f71c90a688f547509f0930a238bf4d71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13b81204215241fbafa8559733743cfa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a84515579394b57a20ad00596198f22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "51998b3fba3e49d5a1d29a7b3cb2d206": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7cc4d6052a240b49df4e2cabf57350b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c437eedd39f64e5b9e07d8b9df0778e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4401d3ed94aa47daa180a939f3f2df8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eec588941b8346b8a493324c29135e6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_412bd2a374b849ea9d259f72f54ecc80",
              "IPY_MODEL_e0bc3c0ca706406f95c6105203f6a56d",
              "IPY_MODEL_2f7c08f384234c668b4a47a9e537d69b"
            ],
            "layout": "IPY_MODEL_374df8cde84a4c0499e9c7def84c8113"
          }
        },
        "412bd2a374b849ea9d259f72f54ecc80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76285dc45dfd4a59a4cc53dfeb41467d",
            "placeholder": "​",
            "style": "IPY_MODEL_ab35d07d63354653971df10c801d4d78",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "e0bc3c0ca706406f95c6105203f6a56d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_61b5b42a4089497a8d82fc98a6f2359a",
            "max": 72,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d7ed904e88e1456685e9db0ce7f60fb1",
            "value": 72
          }
        },
        "2f7c08f384234c668b4a47a9e537d69b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5586de362974da0920b5307158cbea2",
            "placeholder": "​",
            "style": "IPY_MODEL_dafca72f639142b9a6f42344c8117823",
            "value": " 72.0/72.0 [00:00&lt;00:00, 3.90kB/s]"
          }
        },
        "374df8cde84a4c0499e9c7def84c8113": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76285dc45dfd4a59a4cc53dfeb41467d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab35d07d63354653971df10c801d4d78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "61b5b42a4089497a8d82fc98a6f2359a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7ed904e88e1456685e9db0ce7f60fb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c5586de362974da0920b5307158cbea2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dafca72f639142b9a6f42344c8117823": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/uc2045/genai-projects/blob/master/Nov%2017%20WS%20LC1_LangChain_Essentials_Model_I_O.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install OpenAI, HuggingFace and LangChain dependencies"
      ],
      "metadata": {
        "id": "L1KvMtf54l0d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain==0.1.16\n",
        "!pip install langchain-openai==0.1.3\n",
        "!pip install langchain-community==0.0.33\n",
        "!pip install huggingface_hub==0.20.3"
      ],
      "metadata": {
        "id": "2evPp14fy258",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94002391-6f68-4016-f6c3-f6b059af2c16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain==0.1.16\n",
            "  Downloading langchain-0.1.16-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.16) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.16) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.16) (3.10.10)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.16) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain==0.1.16)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.16) (1.33)\n",
            "Collecting langchain-community<0.1,>=0.0.32 (from langchain==0.1.16)\n",
            "  Downloading langchain_community-0.0.38-py3-none-any.whl.metadata (8.7 kB)\n",
            "Collecting langchain-core<0.2.0,>=0.1.42 (from langchain==0.1.16)\n",
            "  Downloading langchain_core-0.1.53-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting langchain-text-splitters<0.1,>=0.0.1 (from langchain==0.1.16)\n",
            "  Downloading langchain_text_splitters-0.0.2-py3-none-any.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.16) (0.1.142)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.16) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.16) (2.9.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.16) (2.32.3)\n",
            "Collecting tenacity<9.0.0,>=8.1.0 (from langchain==0.1.16)\n",
            "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.16) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.16) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.16) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.16) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.16) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.16) (1.17.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.16)\n",
            "  Downloading marshmallow-3.23.1-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.16)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain==0.1.16) (3.0.0)\n",
            "Collecting packaging<24.0,>=23.2 (from langchain-core<0.2.0,>=0.1.42->langchain==0.1.16)\n",
            "  Downloading packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.1.16) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.1.16) (3.10.11)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.1.16) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.1.16) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.1.16) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.1.16) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.1.16) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.1.16) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.1.16) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.1.16) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.1.16) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.1.16) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.1.16) (1.0.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.1.16) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.1.16) (0.14.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.1.16)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain==0.1.16) (0.2.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.1.16) (1.2.2)\n",
            "Downloading langchain-0.1.16-py3-none-any.whl (817 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m817.7/817.7 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading langchain_community-0.0.38-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.1.53-py3-none-any.whl (303 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m303.1/303.1 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-0.0.2-py3-none-any.whl (23 kB)\n",
            "Downloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
            "Downloading marshmallow-3.23.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: tenacity, packaging, mypy-extensions, typing-inspect, marshmallow, dataclasses-json, langchain-core, langchain-text-splitters, langchain-community, langchain\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.0.0\n",
            "    Uninstalling tenacity-9.0.0:\n",
            "      Successfully uninstalled tenacity-9.0.0\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.2\n",
            "    Uninstalling packaging-24.2:\n",
            "      Successfully uninstalled packaging-24.2\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.17\n",
            "    Uninstalling langchain-core-0.3.17:\n",
            "      Successfully uninstalled langchain-core-0.3.17\n",
            "  Attempting uninstall: langchain-text-splitters\n",
            "    Found existing installation: langchain-text-splitters 0.3.2\n",
            "    Uninstalling langchain-text-splitters-0.3.2:\n",
            "      Successfully uninstalled langchain-text-splitters-0.3.2\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.7\n",
            "    Uninstalling langchain-0.3.7:\n",
            "      Successfully uninstalled langchain-0.3.7\n",
            "Successfully installed dataclasses-json-0.6.7 langchain-0.1.16 langchain-community-0.0.38 langchain-core-0.1.53 langchain-text-splitters-0.0.2 marshmallow-3.23.1 mypy-extensions-1.0.0 packaging-23.2 tenacity-8.5.0 typing-inspect-0.9.0\n",
            "Collecting langchain-openai==0.1.3\n",
            "  Downloading langchain_openai-0.1.3-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: langchain-core<0.2.0,>=0.1.42 in /usr/local/lib/python3.10/dist-packages (from langchain-openai==0.1.3) (0.1.53)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from langchain-openai==0.1.3) (1.54.4)\n",
            "Collecting tiktoken<1,>=0.5.2 (from langchain-openai==0.1.3)\n",
            "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.42->langchain-openai==0.1.3) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.42->langchain-openai==0.1.3) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.42->langchain-openai==0.1.3) (0.1.142)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.42->langchain-openai==0.1.3) (23.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.42->langchain-openai==0.1.3) (2.9.2)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.42->langchain-openai==0.1.3) (8.5.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai==0.1.3) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai==0.1.3) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai==0.1.3) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai==0.1.3) (0.7.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai==0.1.3) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai==0.1.3) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai==0.1.3) (4.12.2)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.5.2->langchain-openai==0.1.3) (2024.9.11)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.5.2->langchain-openai==0.1.3) (2.32.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.10.0->langchain-openai==0.1.3) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.10.0->langchain-openai==0.1.3) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai==0.1.3) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai==0.1.3) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai==0.1.3) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.42->langchain-openai==0.1.3) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.42->langchain-openai==0.1.3) (3.10.11)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.42->langchain-openai==0.1.3) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.42->langchain-openai==0.1.3) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.42->langchain-openai==0.1.3) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.5.2->langchain-openai==0.1.3) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.5.2->langchain-openai==0.1.3) (2.2.3)\n",
            "Downloading langchain_openai-0.1.3-py3-none-any.whl (33 kB)\n",
            "Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Don't run if you want to use only chatgpt\n",
        "!pip install transformers"
      ],
      "metadata": {
        "id": "ikRH0Xh-BS3q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Enter API Tokens"
      ],
      "metadata": {
        "id": "PtBa7rlWJWH3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# skip if only using chatgpt\n",
        "from getpass import getpass\n",
        "\n",
        "HUGGINGFACEHUB_API_TOKEN = getpass('Enter HuggingFace API Token: ')"
      ],
      "metadata": {
        "id": "Av1UpSgXZUsI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34b55d6f-3b3a-4372-a364-d1152a1fa48e"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter HuggingFace API Token: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from getpass import getpass\n",
        "\n",
        "OPENAI_KEY = getpass('Enter Open AI API Key: ')"
      ],
      "metadata": {
        "id": "9ogxBkS6ZnnC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ad8144d-04df-465d-b92c-4884b449503a"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter Open AI API Key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "if using Azure Open AI you might need to configure it based on how it is setup in your org.\n",
        "\n",
        "Refer to [this](https://python.langchain.com/docs/integrations/llms/azure_openai/) for more details"
      ],
      "metadata": {
        "id": "T5rOqCyianbP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ['HUGGINGFACEHUB_API_TOKEN'] = HUGGINGFACEHUB_API_TOKEN\n",
        "os.environ['OPENAI_API_KEY'] = OPENAI_KEY"
      ],
      "metadata": {
        "id": "1PIStD04Zp9p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model I/O\n",
        "\n",
        "In LangChain, the central part of any application is the language model. This module provides crucial tools for working effectively with any language model, ensuring it integrates smoothly and communicates well.\n",
        "\n",
        "### Key Components of Model I/O\n",
        "\n",
        "**LLMs and Chat Models (used interchangeably):**\n",
        "- **LLMs:**\n",
        "  - **Definition:** Pure text completion models.\n",
        "  - **Input/Output:** Receives a text string and returns a text string.\n",
        "- **Chat Models:**\n",
        "  - **Definition:** Based on a language model but with different input and output types.\n",
        "  - **Input/Output:** Takes a list of chat messages as input and produces a chat message as output.\n",
        "- **Prompts:** Helps in creating adaptable and context-sensitive prompts that direct the responses of the language model.\n",
        "- **Output Parsers:** Helps in extracting and shaping information from the outputs of language models. This is valuable for turning the language model's raw output into structured data or specific formats needed\n"
      ],
      "metadata": {
        "id": "aqX0BkkWZ_e0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chat Models and LLMs"
      ],
      "metadata": {
        "id": "kai2VrJ1m7q9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "# from langchain_openai import AzureChatOpenAI <- if you are running on Azure you might need this\n",
        "# refer to this for Azure Chat Open AI: https://python.langchain.com/docs/integrations/chat/azure_chat_openai/\n",
        "chatgpt = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)"
      ],
      "metadata": {
        "id": "v8nnrOGxZ2uZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"Explain what is Generative AI?\"\"\"\n",
        "print(prompt)"
      ],
      "metadata": {
        "id": "QDJ8dDFlbWP4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10600b1b-2e6c-4fa4-996d-eb3b96375544"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Explain what is Generative AI?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = chatgpt.invoke(prompt)\n",
        "response"
      ],
      "metadata": {
        "id": "tYym2ioWb-Mw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbe82758-cbb6-4310-dde9-ebb14eb0f5af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='Generative AI refers to a type of artificial intelligence that is capable of creating new content, such as images, text, or music, that is original and not based on existing data. This type of AI uses algorithms to generate new content by learning patterns and structures from a given dataset and then creating new content based on those patterns. Generative AI can be used in a variety of applications, such as creating realistic images, generating text for chatbots, or composing music. It is often used in creative fields where original content creation is important.', response_metadata={'token_usage': {'completion_tokens': 108, 'prompt_tokens': 15, 'total_tokens': 123}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-edaf543f-a1a6-47e2-b5bd-10839abcbc5b-0')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response.content"
      ],
      "metadata": {
        "id": "uehA4Tcdco8G",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "0213eb17-1b3c-4eba-d304-57533d30e75c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Generative AI refers to a type of artificial intelligence that is capable of creating new content, such as images, text, or music, that is original and not based on existing data. This type of AI uses algorithms to generate new content by learning patterns and structures from a given dataset and then creating new content based on those patterns. Generative AI can be used in a variety of applications, such as creating realistic images, generating text for chatbots, or composing music. It is often used in creative fields where original content creation is important.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.llms import HuggingFaceEndpoint\n",
        "\n",
        "MISTRAL7B_API_URL = \"https://api-inference.huggingface.co/models/mistralai/Mistral-7B-Instruct-v0.2\"\n",
        "mistral_params = {\n",
        "                  \"wait_for_model\": True,\n",
        "                  \"do_sample\": False,\n",
        "                  \"return_full_text\": False,\n",
        "                  \"max_new_tokens\": 1000,\n",
        "                }\n",
        "llm = HuggingFaceEndpoint(\n",
        "    endpoint_url=MISTRAL7B_API_URL,\n",
        "    task=\"text-generation\",\n",
        "    **mistral_params\n",
        ")\n"
      ],
      "metadata": {
        "id": "1fgv8DhwcCWD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cb68f8b-0733-4e16-fb97-bf7b17830ad7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_community.llms.huggingface_endpoint:WARNING! wait_for_model is not default parameter.\n",
            "                    wait_for_model was transferred to model_kwargs.\n",
            "                    Please make sure that wait_for_model is what you intended.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: write).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt"
      ],
      "metadata": {
        "id": "4LMB-dezWeRR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "16c93564-1350-4fb3-9d5f-11467b3a7a8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Explain what is Generative AI?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm.invoke(prompt)"
      ],
      "metadata": {
        "id": "sy2DDI6He97g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "outputId": "34b672f3-e213-4898-ada8-71baa5b76c5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\nGenerative AI refers to a type of artificial intelligence that can create new, original content, such as text, images, audio, or even music, based on the data it has been trained on. This is achieved by using algorithms that can generate new instances of data that resemble the training data but are not identical to it.\\n\\nGenerative AI models work by learning the underlying patterns and structures in the training data and then using that knowledge to generate new content that follows those patterns. The most common type of generative AI is based on deep learning, specifically deep neural networks, such as recurrent neural networks (RNNs), long short-term memory networks (LSTMs), and generative adversarial networks (GANs).\\n\\nGenerative AI has many applications, including but not limited to:\\n- Content creation for media and entertainment industries, such as generating music, videos, and images.\\n- Text generation for applications like chatbots, language translation, and writing assistants.\\n- Data augmentation for machine learning models, allowing for more diverse and representative training data.\\n- Art and design, such as generating new and unique visual art or architectural designs.\\n- Scientific research, such as generating new molecules for drug discovery or generating new data for climate modeling.\\n\\nGenerative AI is a rapidly growing field, with new applications and advancements being discovered all the time. It holds great promise for transforming industries and creating new opportunities for innovation and creativity. However, it also raises important ethical and societal questions, such as the potential for misuse, the impact on employment, and the role of AI in human creativity.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.chat_models import ChatHuggingFace\n",
        "\n",
        "hf_mistral = ChatHuggingFace(llm=llm, model_id='mistralai/Mistral-7B-Instruct-v0.2')"
      ],
      "metadata": {
        "id": "auoQdEoNd8l2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269,
          "referenced_widgets": [
            "f73178061a614878a24c8f42946ef0f1",
            "7ce1c6ea73764acea5bcd6d4d1102326",
            "82670de5446345928b5c831406bd41e1",
            "24534a1566a547428d20cad9b96722e4",
            "de4f934c4ae44c1abe845b3c200a57fb",
            "363f83b8faaf4f48a76fa45e7800ca7b",
            "464dbd5933b54a898d63d5843aeedaa8",
            "3b00ea2688de48028f1346de11a73cfc",
            "fdae9037908d4bf5b937a7a147e6e092",
            "842a3200dc1248d9b4725b8f1e07331e",
            "46948329be9b44feb201005e857aeb1e",
            "3b3818e6a4f24e88bf6fdeaa285437ee",
            "48e6567719574bc7a44c6e6849cbc523",
            "5e7813887d644e0a99a976f75674355a",
            "d56eec56e62d422ca82bc734bd9c01a6",
            "e042b8a8cc14493f9a65f509634394aa",
            "9952412c6424413788f44b92c11438c1",
            "12e0f036b22f4789acdd758a87e714d9",
            "a5fd596303e34733925477a3ce8eaccf",
            "fa01f4d390634438a05ba651dba65c51",
            "f663e5c120d445689b6621004dcb955b",
            "d2a24d37ceca4c4db172cd619c5d905f",
            "382ddd827ee044dda40113f69883091d",
            "9ca7ffb301934499a8737b1162f6b316",
            "b4bb1155db2f4224899f12da88dccddf",
            "dc9b79e653c14a33b695a909f143187d",
            "f71c90a688f547509f0930a238bf4d71",
            "13b81204215241fbafa8559733743cfa",
            "6a84515579394b57a20ad00596198f22",
            "51998b3fba3e49d5a1d29a7b3cb2d206",
            "b7cc4d6052a240b49df4e2cabf57350b",
            "c437eedd39f64e5b9e07d8b9df0778e7",
            "4401d3ed94aa47daa180a939f3f2df8f",
            "eec588941b8346b8a493324c29135e6d",
            "412bd2a374b849ea9d259f72f54ecc80",
            "e0bc3c0ca706406f95c6105203f6a56d",
            "2f7c08f384234c668b4a47a9e537d69b",
            "374df8cde84a4c0499e9c7def84c8113",
            "76285dc45dfd4a59a4cc53dfeb41467d",
            "ab35d07d63354653971df10c801d4d78",
            "61b5b42a4089497a8d82fc98a6f2359a",
            "d7ed904e88e1456685e9db0ce7f60fb1",
            "c5586de362974da0920b5307158cbea2",
            "dafca72f639142b9a6f42344c8117823"
          ]
        },
        "outputId": "91f80297-4f1f-48ec-9dc5-301d6d23da67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.46k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f73178061a614878a24c8f42946ef0f1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3b3818e6a4f24e88bf6fdeaa285437ee"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "382ddd827ee044dda40113f69883091d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/72.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eec588941b8346b8a493324c29135e6d"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = hf_mistral.invoke(prompt)\n",
        "response"
      ],
      "metadata": {
        "id": "4Jxxt45gex29",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c52f1e5-6034-4d6e-e0fa-dd4c285528e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content=' Generative Artificial Intelligence (AI) refers to a type of machine learning models that can create new content, such as images, text, or music, based on patterns and data it has been trained on. These models use probabilistic algorithms to generate outputs that resemble the training data, but are not exact copies. Instead, they create unique and sometimes surprising results that can vary each time the model is run.\\n\\nGenerative AI models learn to understand the underlying structure and distribution of the data they are trained on, allowing them to generate new, synthetic data that mimics the real data. This is in contrast to discriminative models, which learn to identify and classify data points based on their features.\\n\\nSome popular types of generative AI models include:\\n\\n1. Generative Adversarial Networks (GANs): A deep learning model that consists of two parts: a generator network that creates new data and a discriminator network that evaluates the authenticity of the data. The two networks are trained together in a process called adversarial training, which helps the generator to create more realistic data.\\n\\n2. Variational Autoencoders (VAEs): A deep learning model that learns a probabilistic representation of the data, allowing it to generate new data by sampling from the learned distribution.\\n\\n3. Recurrent Neural Networks (RNNs) and Long Short-Term Memory (LSTM) networks: A type of neural network that can process sequential data, such as text or speech. These models can generate new text or speech by generating probabilities for the next word or phoneme based on the previous ones.\\n\\nGenerative AI has many potential applications, including creating art, writing stories, composing music, generating new designs for products, and even generating realistic 3D models for video games or virtual reality environments. It is an exciting and rapidly evolving field, with many new developments and applications on the horizon.', id='run-2caf0f4f-a682-4e5e-8137-dc44123c6081-0')"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.content)"
      ],
      "metadata": {
        "id": "vhrRC7HiiKAR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "914402cb-3f6f-450a-e8f8-c2f40e4387d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Generative Artificial Intelligence (AI) refers to a type of machine learning models that can create new content, such as images, text, or music, based on patterns and data it has been trained on. These models use probabilistic algorithms to generate outputs that resemble the training data, but are not exact copies. Instead, they create unique and sometimes surprising results that can vary each time the model is run.\n",
            "\n",
            "Generative AI models learn to understand the underlying structure and distribution of the data they are trained on, allowing them to generate new, synthetic data that mimics the real data. This is in contrast to discriminative models, which learn to identify and classify data points based on their features.\n",
            "\n",
            "Some popular types of generative AI models include:\n",
            "\n",
            "1. Generative Adversarial Networks (GANs): A deep learning model that consists of two parts: a generator network that creates new data and a discriminator network that evaluates the authenticity of the data. The two networks are trained together in a process called adversarial training, which helps the generator to create more realistic data.\n",
            "\n",
            "2. Variational Autoencoders (VAEs): A deep learning model that learns a probabilistic representation of the data, allowing it to generate new data by sampling from the learned distribution.\n",
            "\n",
            "3. Recurrent Neural Networks (RNNs) and Long Short-Term Memory (LSTM) networks: A type of neural network that can process sequential data, such as text or speech. These models can generate new text or speech by generating probabilities for the next word or phoneme based on the previous ones.\n",
            "\n",
            "Generative AI has many potential applications, including creating art, writing stories, composing music, generating new designs for products, and even generating realistic 3D models for video games or virtual reality environments. It is an exciting and rapidly evolving field, with many new developments and applications on the horizon.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Message Types\n",
        "\n",
        "ChatModels process a list of messages, receiving them as input and responding with a message. Messages are characterized by a few distinct types and properties:\n",
        "\n",
        "- **Role:** Indicates who is speaking in the message. LangChain offers different message classes for various roles.\n",
        "- **Content:** The substance of the message, which can vary:\n",
        "  - A string (commonly handled by most models)\n",
        "  - A list of dictionaries (for multi-modal inputs, where each dictionary details the type and location of the input)\n",
        "\n",
        "Additionally, messages have an `additional_kwargs` property, used for passing extra information specific to the message provider, not typically general. A well-known example is `function_call` from OpenAI.\n",
        "\n",
        "### Specific Message Types\n",
        "\n",
        "- **HumanMessage:** A user-generated message, usually containing only content.\n",
        "- **AIMessage:** A message from the model, potentially including `additional_kwargs`, like `tool_calls` for invoking OpenAI tools.\n",
        "- **SystemMessage:** A message from the system instructing model behavior, typically containing only content. Not all models support this type.\n"
      ],
      "metadata": {
        "id": "L7kLCJevjCe_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chatgpt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bCLGlujf-s0J",
        "outputId": "546e51d7-ba48-40a7-ed5f-d6f6e024946e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x7b67b7ffc670>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7b67b7ffdd80>, temperature=0.0, openai_api_key=SecretStr('**********'), openai_proxy='')"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "\n",
        "prompt = \"\"\"Can you explain what is Generative AI in 3 bullet points?\"\"\"\n",
        "\n",
        "messages = [\n",
        "    SystemMessage(content=\"Act as a helpful assistant.\"),\n",
        "    HumanMessage(content=prompt),\n",
        "]\n",
        "\n",
        "messages"
      ],
      "metadata": {
        "id": "uKDMkowiiNjG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37c7f1f0-d723-4d4a-c3da-b74509724a65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[SystemMessage(content='Act as a helpful assistant.'),\n",
              " HumanMessage(content='Can you explain what is Generative AI in 3 bullet points?')]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = chatgpt.invoke(messages)\n",
        "response"
      ],
      "metadata": {
        "id": "xizcAMNKjYSk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "916b75aa-538d-42cf-c1ad-94e1a9ba58e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='- Generative AI is a type of artificial intelligence that is capable of creating new content, such as images, text, or music, based on patterns and data it has been trained on.\\n- It works by learning the underlying structure of the data it is trained on and then generating new content that is similar to the original data.\\n- Generative AI has applications in various fields, including art, design, and even drug discovery, where it can help generate new ideas and solutions.', response_metadata={'token_usage': {'completion_tokens': 96, 'prompt_tokens': 31, 'total_tokens': 127}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-e526c91a-065a-4b47-8acb-400c7a4b208d-0')"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.content)"
      ],
      "metadata": {
        "id": "BrYfYw8Ijhjz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89378b72-0d09-4e2e-841a-8ca98becc08a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- Generative AI is a type of artificial intelligence that is capable of creating new content, such as images, text, or music, based on patterns and data it has been trained on.\n",
            "- It works by learning the underlying structure of the data it is trained on and then generating new content that is similar to the original data.\n",
            "- Generative AI has applications in various fields, including art, design, and even drug discovery, where it can help generate new ideas and solutions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages.append(response)\n",
        "\n",
        "prompt = \"\"\"What did we discuss so far?\"\"\"\n",
        "messages.append(HumanMessage(content=prompt))\n",
        "messages"
      ],
      "metadata": {
        "id": "R5qvveyhjksA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81a6ce00-86c3-4b1c-fa27-f5dc4cc55087"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[SystemMessage(content='Act as a helpful assistant.'),\n",
              " HumanMessage(content='Can you explain what is Generative AI in 3 bullet points?'),\n",
              " AIMessage(content='- Generative AI is a type of artificial intelligence that is capable of creating new content, such as images, text, or music, based on patterns and data it has been trained on.\\n- It works by learning the underlying structure of the data it is trained on and then generating new content that is similar to the original data.\\n- Generative AI has applications in various fields, including art, design, and even drug discovery, where it can help generate new ideas and solutions.', response_metadata={'token_usage': {'completion_tokens': 96, 'prompt_tokens': 31, 'total_tokens': 127}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-e526c91a-065a-4b47-8acb-400c7a4b208d-0'),\n",
              " HumanMessage(content='What did we discuss so far?')]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = chatgpt.invoke(messages)\n",
        "response.content"
      ],
      "metadata": {
        "id": "O8dQjk-Cj15m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "148af04a-860d-42b4-9e29-5e1c1e587229"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'So far, we have discussed Generative AI and its key characteristics in three bullet points. If you have any more questions or need further clarification on this topic or any other topic, feel free to ask!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# not needed if you are only running chatgpt\n",
        "# this runs prompts using the open source LLM - however mistral doesnt support a system prompt\n",
        "prompt = \"\"\"Can you explain what is Generative AI in 3 bullet points?\"\"\"\n",
        "messages = [\n",
        "    HumanMessage(content=prompt),\n",
        "]\n",
        "\n",
        "response = hf_mistral.invoke(messages) # doesn't support system prompts\n",
        "print(response.content)"
      ],
      "metadata": {
        "id": "qHsTawgsj4Nd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "005f4b47-ee2e-4c61-96a5-740ccc958c17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1. Generative AI is a type of artificial intelligence that can create new content, such as images, text, or music, by learning patterns from existing data and using that knowledge to generate new, original content.\n",
            "2. It differs from discriminative AI, which focuses on identifying and classifying existing data, by actively generating new data based on learned patterns.\n",
            "3. Generative AI models can be trained using techniques such as deep learning, recurrent neural networks, and generative adversarial networks (GANs), and have applications in areas like art and design, natural language processing, and music composition.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prompt Templates\n",
        "Prompt templates are pre-designed formats used to generate prompts for language models. These templates can include instructions, few-shot examples, and specific contexts and questions suited for particular tasks.\n",
        "\n",
        "LangChain provides tools for creating and using prompt templates. It aims to develop model-agnostic templates to facilitate the reuse of existing templates across different language models. Typically, these models expect prompts in the form of either a string or a list of chat messages.\n",
        "\n",
        "### Types of Prompt Templates\n",
        "\n",
        "- **PromptTemplate:**\n",
        "  - Used for creating string-based prompts.\n",
        "  - Utilizes Python's `str.format` syntax for templating, supporting any number of variables, including scenarios with no variables.\n",
        "\n",
        "- **ChatPromptTemplate:**\n",
        "  - Designed for chat models, where the prompt consists of a list of chat messages.\n",
        "  - Each chat message includes content and a role parameter. For instance, in the OpenAI Chat Completions API, a chat message could be assigned to an AI assistant, a human, or a system role.\n",
        "\n"
      ],
      "metadata": {
        "id": "8i8KIVTwnD6Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### PromptTemplate"
      ],
      "metadata": {
        "id": "7Oh9UiTNqaPf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "# Simple prompt\n",
        "\n",
        "prompt = \"\"\"Explain to me what is Generative AI in 3 bullet points?\"\"\"\n",
        "prompt_template = PromptTemplate.from_template(prompt)\n",
        "prompt_template"
      ],
      "metadata": {
        "id": "xoUCbb4FkaIW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a526f8af-0c15-44cd-fbea-7221b751f303"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PromptTemplate(input_variables=[], template='Explain to me what is Generative AI in 3 bullet points?')"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template.format()"
      ],
      "metadata": {
        "id": "nPNs1Efsn2Zf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "69bd93e6-c476-44ef-e5c1-eeaac61028be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Explain to me what is Generative AI in 3 bullet points?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = chatgpt.invoke(prompt_template.format())\n",
        "print(response.content)"
      ],
      "metadata": {
        "id": "iM5oNvXpnSq7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "619b6fa7-15e4-47f9-ad3e-025956b544dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- Generative AI is a type of artificial intelligence that is capable of creating new content, such as images, text, or music, based on patterns and data it has been trained on.\n",
            "- It uses algorithms and neural networks to generate original and unique outputs that mimic human creativity and intelligence.\n",
            "- Generative AI has a wide range of applications, including creating art, generating realistic images, composing music, and even writing stories or poems.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# more complex prompt with placeholders\n",
        "prompt = \"\"\"Explain to me briefly about {topic} in {language}.\"\"\"\n",
        "\n",
        "prompt_template = PromptTemplate.from_template(prompt)\n",
        "prompt_template"
      ],
      "metadata": {
        "id": "2VTvciVcnajD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8edd5aaa-dc8c-4ff4-806e-c8e477c8e1c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PromptTemplate(input_variables=['language', 'topic'], template='Explain to me briefly about {topic} in {language}.')"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = [(\"Artificial Intelligence\", \"english\"),\n",
        "          (\"Artificial Intelligence\", \"hindi\")]\n",
        "\n",
        "prompts = [prompt_template.format(topic=topic, language=language) for topic, language in inputs]\n",
        "prompts"
      ],
      "metadata": {
        "id": "FyXhUhbapZ7T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f424c41-e50e-4ff3-9aa4-82ca5a58c343"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Explain to me briefly about Artificial Intelligence in english.',\n",
              " 'Explain to me briefly about Artificial Intelligence in hindi.']"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "responses = chatgpt.map().invoke(prompts)"
      ],
      "metadata": {
        "id": "edPyCf_Aps9Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "responses"
      ],
      "metadata": {
        "id": "wZ8cDck4ck_g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6adc9ba5-f3e9-4c0b-cd92-25c1f3d451aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[AIMessage(content='Artificial Intelligence (AI) is a branch of computer science that focuses on creating machines that can perform tasks that typically require human intelligence, such as learning, problem-solving, and decision-making. AI systems are designed to analyze data, recognize patterns, and make predictions or decisions based on that information. AI technology is used in a wide range of applications, from virtual assistants like Siri and Alexa to self-driving cars and medical diagnosis systems. The goal of AI is to create machines that can mimic human cognitive functions and improve efficiency and accuracy in various tasks.', response_metadata={'token_usage': {'completion_tokens': 109, 'prompt_tokens': 18, 'total_tokens': 127}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-2d91b71a-d447-4919-a03b-34f59d52d8bf-0'),\n",
              " AIMessage(content='कृत्रिम बुद्धिमत्ता एक शाखा है जो कंप्यूटर और मशीनों को मानव बुद्धिमत्ता की तरह काम करने की क्षमता प्रदान करती है। यह तकनीकी उन्नति का एक महत्वपूर्ण क्षेत्र है जो विभिन्न क्षेत्रों में उपयोग किया जाता है, जैसे कि रोबोटिक्स, विज्ञान, चिकित्सा, वित्त और अन्य। इसका उद्देश्य है मशीनों को स्वयं सोचने, सीखने और समस्याओं का समाधान करने की क्षमता प्रदान करना।', response_metadata={'token_usage': {'completion_tokens': 340, 'prompt_tokens': 18, 'total_tokens': 358}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-497f19d0-9ac4-499e-9ea4-c9dadc120af3-0')]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for response in responses:\n",
        "  print(response.content)\n",
        "  print('-----')"
      ],
      "metadata": {
        "id": "tRWUf9eTqEMU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e83e31d-9f11-4f93-a1e5-cfea08580645"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Artificial Intelligence (AI) is a branch of computer science that focuses on creating machines that can perform tasks that typically require human intelligence, such as learning, problem-solving, and decision-making. AI systems are designed to analyze data, recognize patterns, and make predictions or decisions based on that information. AI technology is used in a wide range of applications, from virtual assistants like Siri and Alexa to self-driving cars and medical diagnosis systems. The goal of AI is to create machines that can mimic human cognitive functions and improve efficiency and accuracy in various tasks.\n",
            "-----\n",
            "कृत्रिम बुद्धिमत्ता एक शाखा है जो कंप्यूटर और मशीनों को मानव बुद्धिमत्ता की तरह काम करने की क्षमता प्रदान करती है। यह तकनीकी उन्नति का एक महत्वपूर्ण क्षेत्र है जो विभिन्न क्षेत्रों में उपयोग किया जाता है, जैसे कि रोबोटिक्स, विज्ञान, चिकित्सा, वित्त और अन्य। इसका उद्देश्य है मशीनों को स्वयं सोचने, सीखने और समस्याओं का समाधान करने की क्षमता प्रदान करना।\n",
            "-----\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ChatPromptTemplate"
      ],
      "metadata": {
        "id": "VAGmjR-tqfmV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "# more complex prompt with placeholders\n",
        "prompt = \"\"\"Explain to me briefly about {topic}.\"\"\"\n",
        "\n",
        "chat_template = ChatPromptTemplate.from_template(prompt)\n",
        "chat_template"
      ],
      "metadata": {
        "id": "tawdWLueqHG6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbb056ca-7183-4d0c-f098-e53f72a5821e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['topic'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['topic'], template='Explain to me briefly about {topic}.'))])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "topics = ['Generative AI', 'Machine Learning', 'Deep Learning']\n",
        "prompts = [chat_template.format(topic=topic) for topic in topics]\n",
        "prompts"
      ],
      "metadata": {
        "id": "Hr0sC7xHqxOp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b05fa08d-ea51-417c-cec0-691f142b833d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Human: Explain to me briefly about Generative AI.',\n",
              " 'Human: Explain to me briefly about Machine Learning.',\n",
              " 'Human: Explain to me briefly about Deep Learning.']"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "responses = chatgpt.map().invoke(prompts)\n",
        "for response in responses:\n",
        "  print(response.content)\n",
        "  print('-----')"
      ],
      "metadata": {
        "id": "cU9YObv9rY4P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26d18187-4d9c-4fc2-b151-cbe6b5ca4a15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generative AI refers to a type of artificial intelligence that is capable of creating new content, such as images, text, or music, based on patterns and data it has been trained on. This technology can be used for a variety of applications, including creating realistic images, generating human-like text, and composing music. Generative AI has the potential to revolutionize many industries by automating the creative process and generating new and innovative content.\n",
            "-----\n",
            "Machine learning is a subset of artificial intelligence that involves the development of algorithms and statistical models that enable computers to learn from and make predictions or decisions based on data without being explicitly programmed. It uses patterns and inference to make decisions and improve over time as it is exposed to more data.\n",
            "-----\n",
            "Deep learning is a subset of machine learning that uses artificial neural networks to model and solve complex problems. It involves training these neural networks on large amounts of data to learn patterns and make predictions or decisions. Deep learning has been successful in various applications such as image and speech recognition, natural language processing, and autonomous driving.\n",
            "-----\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "responses[0]"
      ],
      "metadata": {
        "id": "8NHhUa48rm_g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7583c79f-442a-4868-ceab-746fbaec7252"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='Generative AI refers to a type of artificial intelligence that is capable of creating new content, such as images, text, or music, based on patterns and data it has been trained on. This technology can be used for a variety of applications, including creating realistic images, generating human-like text, and composing music. Generative AI has the potential to revolutionize many industries by automating the creative process and generating new and innovative content.', response_metadata={'token_usage': {'completion_tokens': 87, 'prompt_tokens': 18, 'total_tokens': 105}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-7608b31d-55d0-482b-aeb4-dc45d5c61bb2-0')"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dont use if you are only using chatgpt\n",
        "responses = hf_mistral.map().invoke(prompts)\n",
        "for response in responses:\n",
        "  print(response.content)\n",
        "  print('-----')"
      ],
      "metadata": {
        "id": "VAqp1gLjrdza",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "233f754e-9221-4daa-d2ad-61373304e9d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Generative Artificial Intelligence (AI) is a subset of machine learning and artificial intelligence that can create new content, including images, text, music, and even speech. It's called \"generative\" because it can generate entirely new data that wasn't in its training dataset.\n",
            "\n",
            "Generative AI models learn the underlying patterns and structures of data, enabling them to generate new, unique content. They do this by using complex mathematical models and algorithms, such as Variational Autoencoders (VAEs), Generative Adversarial Networks (GANs), and Transformer models.\n",
            "\n",
            "These models are trained on large datasets, which they use as a guide to learn how to create new content. For example, a generative AI model might be trained on thousands of images of dogs. Once trained, it can generate new images of dogs that it hasn't seen before.\n",
            "\n",
            "Generative AI has many applications, including creating art, generating text for novels or articles, composing music, and even generating speech for virtual assistants or chatbots. It's an exciting area of research and development, as it has the potential to create new content that was previously impossible to generate using traditional methods.\n",
            "-----\n",
            " Machine Learning (ML) is a subset of Artificial Intelligence (AI) that provides systems the ability to automatically learn and improve from experience without being explicitly programmed. It focuses on developing models and algorithms that can identify patterns from data and use that knowledge to make predictions or decisions.\n",
            "\n",
            "The process of learning begins with feeding large datasets into a machine learning model. The model uses various techniques such as supervised learning, unsupervised learning, or reinforcement learning to identify and learn from the data.\n",
            "\n",
            "Supervised learning is a type of ML where the data is labeled. The model is trained using this labeled data and uses the knowledge gained to make predictions or decisions about new, unseen data.\n",
            "\n",
            "Unsupervised learning, on the other hand, is used when the data is not labeled. The model looks for hidden patterns or structures within the data and groups similar data together.\n",
            "\n",
            "Reinforcement learning is a type of ML where the model learns by interacting with its environment and receiving feedback in the form of rewards or penalties. The model uses this feedback to make better decisions in the future.\n",
            "\n",
            "Machine learning applications are vast and can be found in various industries including healthcare, finance, marketing, and more. Some common applications include email filtering, recommendation systems, fraud detection, and speech recognition.\n",
            "\n",
            "Overall, machine learning is an exciting and powerful technology that has the potential to transform industries and improve our daily lives.\n",
            "-----\n",
            " Deep Learning is a subfield of Machine Learning, which is a method of Artificial Intelligence that modeles its workings after the human brain. It is called \"deep\" because of the neural networks' depth or the number of layers between the input and output layers.\n",
            "\n",
            "Deep Learning algorithms are inspired by the structure and function of the brain's neocortex, which is responsible for processing sensory input in humans and animals. These algorithms can learn and improve from experience, similar to how the human brain does.\n",
            "\n",
            "Deep Learning models consist of multiple interconnected processing layers. Each layer is responsible for learning a specific type of feature. For example, in image recognition, the first layers might learn to detect edges and simple shapes, while the deeper layers might learn to recognize complex objects and patterns.\n",
            "\n",
            "Deep Learning models are trained on large datasets using a process called backpropagation. This involves feeding the model large amounts of data and adjusting the weights between the layers based on the model's performance. This process allows the model to learn the underlying patterns and relationships in the data.\n",
            "\n",
            "Deep Learning has achieved remarkable success in various applications such as image and speech recognition, natural language processing, and game playing. It has surpassed human-level performance in certain tasks, such as recognizing objects in images or transcribing speech.\n",
            "\n",
            "Deep Learning models are particularly effective when dealing with large amounts of data and complex patterns. They can learn to represent data in a more abstract and meaningful way than traditional machine learning algorithms, enabling them to make more accurate predictions and decisions.\n",
            "-----\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "        (\"system\", \"Act as an expert in real estate and provide brief answers\"),\n",
        "        (\"human\", \"what is your name?\"),\n",
        "        (\"ai\", \"my name is AIBot\"),\n",
        "        (\"human\", \"{user_prompt}\"),\n",
        "]\n",
        "chat_template = ChatPromptTemplate.from_messages(messages)\n",
        "chat_template"
      ],
      "metadata": {
        "id": "1PSkafcfsme2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a65a32a4-c15f-48bb-e373-13157e06871a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['user_prompt'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='Act as an expert in real estate and provide brief answers')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='what is your name?')), AIMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='my name is AIBot')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['user_prompt'], template='{user_prompt}'))])"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_prompts = [\"what is your name?\",\n",
        "                \"explain commercial real estate to me\"]\n",
        "chat_prompts = [chat_template.format(user_prompt=prompt) for prompt in text_prompts]\n",
        "chat_prompts"
      ],
      "metadata": {
        "id": "N5ncYrVVtUWU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3885dc1b-0992-4ef9-84c6-5fe015a8997a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['System: Act as an expert in real estate and provide brief answers\\nHuman: what is your name?\\nAI: my name is AIBot\\nHuman: what is your name?',\n",
              " 'System: Act as an expert in real estate and provide brief answers\\nHuman: what is your name?\\nAI: my name is AIBot\\nHuman: explain commercial real estate to me']"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(chat_prompts[1])"
      ],
      "metadata": {
        "id": "vQd1Bk_Td2mM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "122b466d-bf0b-4b8b-923c-7c8f030f3815"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "System: Act as an expert in real estate and provide brief answers\n",
            "Human: what is your name?\n",
            "AI: my name is AIBot\n",
            "Human: explain commercial real estate to me\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "responses = chatgpt.map().invoke(chat_prompts)\n",
        "for response in responses:\n",
        "  print(response.content)\n",
        "  print('-----')"
      ],
      "metadata": {
        "id": "73R370WTuAIR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20fe7d9c-5eb8-4153-8f86-bbd587055bef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AI: I am an AI expert in real estate, how can I assist you today?\n",
            "-----\n",
            "AI: Commercial real estate refers to properties that are used for business purposes, such as office buildings, retail spaces, and industrial facilities. These properties are typically leased or rented out to businesses for their operations.\n",
            "-----\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "        (\"system\", \"Act as an expert in real estate and provide very detailed answers with examples\"),\n",
        "        (\"human\", \"what is your name?\"),\n",
        "        (\"ai\", \"my name is AIBot\"),\n",
        "        (\"human\", \"{user_prompt}\"),\n",
        "]\n",
        "chat_template = ChatPromptTemplate.from_messages(messages)\n",
        "text_prompts = [\"what is your name?\", \"explain commercial real estate to me\"]\n",
        "chat_prompts = [chat_template.format(user_prompt=prompt) for prompt in text_prompts]\n",
        "chat_prompts"
      ],
      "metadata": {
        "id": "qQJP-Q6SuLmV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ac37cea-bbcb-44a8-f24c-3e708350c512"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['System: Act as an expert in real estate and provide very detailed answers with examples\\nHuman: what is your name?\\nAI: my name is AIBot\\nHuman: what is your name?',\n",
              " 'System: Act as an expert in real estate and provide very detailed answers with examples\\nHuman: what is your name?\\nAI: my name is AIBot\\nHuman: explain commercial real estate to me']"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "responses = chatgpt.map().invoke(chat_prompts)\n",
        "for response in responses:\n",
        "  print(response.content)\n",
        "  print('-----')"
      ],
      "metadata": {
        "id": "JK9VxeObuTXj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e329bfd4-c7b5-457f-e3da-d445e0a53a7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AI: My name is AIBot. How can I assist you with real estate questions today?\n",
            "-----\n",
            "AI: Commercial real estate refers to properties that are used for business purposes, such as office buildings, retail spaces, industrial facilities, and hotels. These properties are typically leased or rented out to businesses or individuals for commercial use.\n",
            "\n",
            "Commercial real estate can be a lucrative investment opportunity for individuals or companies looking to generate rental income or increase their asset portfolio. The value of commercial properties is often determined by factors such as location, size, condition, and potential for rental income.\n",
            "\n",
            "For example, a company may purchase an office building in a prime location in a major city to lease out to multiple tenants. The rental income from these tenants can provide a steady stream of revenue for the company, while also potentially increasing the value of the property over time.\n",
            "\n",
            "It's important to note that commercial real estate can be a complex and competitive market, so it's essential to conduct thorough research and due diligence before investing in or leasing commercial properties. Working with a real estate expert or consultant can help navigate the complexities of the commercial real estate market and make informed decisions.\n",
            "-----\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Output Parsers\n",
        "Output parsers are essential in Langchain for structuring the responses from language models. Below, we will discuss the role of output parsers and include examples using Langchain's specific parser types: PydanticOutputParser, JsonOutputParser, and CommaSeparatedListOutputParser.\n",
        "\n",
        "- **Pydantic parser:**\n",
        "  - This parser allows the specification of an arbitrary Pydantic Model to query LLMs for outputs matching that schema. Pydantic's BaseModel functions similarly to a Python dataclass but includes type checking and coercion.\n",
        "\n",
        "- **JSON parser:**\n",
        "  - Users can specify an arbitrary JSON schema with this parser to ensure outputs from LLMs adhere to that schema. Pydantic can also be used to declare your data model here.\n",
        "\n",
        "- **CSV parser:**\n",
        "  - Useful for outputs requiring a list of items separated by commas. This parser facilitates the extraction of comma-separated values from model outputs.\n"
      ],
      "metadata": {
        "id": "-cei3lVfHduK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### JsonOutputParser"
      ],
      "metadata": {
        "id": "qMbwJySEITJy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field\n",
        "\n",
        "\n",
        "# Define your desired data structure - like a python data class.\n",
        "class ITSupportResponse(BaseModel):\n",
        "    orig_msg: str = Field(description=\"The original customer IT support query message\")\n",
        "    orig_lang: str = Field(description=\"Detected language of the customer message e.g. Spanish\")\n",
        "    category: str = Field(description=\"1-2 word describing the category of the problem\")\n",
        "    trans_msg: str = Field(description=\"Translated customer IT support query message in English\")\n",
        "    response: str = Field(description=\"Response to the customer in their original language - orig_lang\")\n",
        "    trans_response: str = Field(description=\"Response to the customer in English\")\n",
        "\n",
        "\n",
        "parser = JsonOutputParser(pydantic_object=ITSupportResponse)\n",
        "parser"
      ],
      "metadata": {
        "id": "Td0hVmQd3OVw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1edd100-9990-406d-fcbf-c0e73c8114a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "JsonOutputParser(pydantic_object=<class '__main__.ITSupportResponse'>)"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(parser.get_format_instructions())"
      ],
      "metadata": {
        "id": "xFIk3rqn4RLS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51432e14-688c-447f-d3dc-c1734ee24bd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
            "\n",
            "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
            "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
            "\n",
            "Here is the output schema:\n",
            "```\n",
            "{\"properties\": {\"orig_msg\": {\"title\": \"Orig Msg\", \"description\": \"The original customer IT support query message\", \"type\": \"string\"}, \"orig_lang\": {\"title\": \"Orig Lang\", \"description\": \"Detected language of the customer message e.g. Spanish\", \"type\": \"string\"}, \"category\": {\"title\": \"Category\", \"description\": \"1-2 word describing the category of the problem\", \"type\": \"string\"}, \"trans_msg\": {\"title\": \"Trans Msg\", \"description\": \"Translated customer IT support query message in English\", \"type\": \"string\"}, \"response\": {\"title\": \"Response\", \"description\": \"Response to the customer in their original language - orig_lang\", \"type\": \"string\"}, \"trans_response\": {\"title\": \"Trans Response\", \"description\": \"Response to the customer in English\", \"type\": \"string\"}}, \"required\": [\"orig_msg\", \"orig_lang\", \"category\", \"trans_msg\", \"response\", \"trans_response\"]}\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# And a query intented to prompt a language model to populate the data structure.\n",
        "prompt_txt = \"\"\"\n",
        "             Act as an Information Technology (IT) customer support agent. For the IT support message mentioned below\n",
        "             in triple backticks use the following format when generating the output response\n",
        "\n",
        "             Output format instructions:\n",
        "             {format_instructions}\n",
        "\n",
        "             Customer IT support message:\n",
        "             ```{it_support_msg}```\n",
        "             \"\"\"\n",
        "\n",
        "\n",
        "# Set up a parser + inject instructions into the prompt template.\n",
        "parser = JsonOutputParser(pydantic_object=ITSupportResponse)\n",
        "\n",
        "prompt = PromptTemplate.from_template(template=prompt_txt)\n",
        "prompt"
      ],
      "metadata": {
        "id": "1HJvSevb4XES",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f980ab3-90fe-4da6-fdd4-8e1b0f8ea7dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PromptTemplate(input_variables=['format_instructions', 'it_support_msg'], template='\\n             Act as an Information Technology (IT) customer support agent. For the IT support message mentioned below\\n             in triple backticks use the following format when generating the output response\\n\\n             Output format instructions:\\n             {format_instructions}\\n\\n             Customer IT support message:\\n             ```{it_support_msg}```\\n             ')"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a simple LLM Chain - more on this later - uses LCEL - langchain expression language\n",
        "llm_chain = (prompt\n",
        "              |\n",
        "            chatgpt\n",
        "              |\n",
        "            parser)\n",
        "llm_chain"
      ],
      "metadata": {
        "id": "ObjYJrXh8Hj3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b00b72c-9416-4363-a764-4e8ea2900010"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PromptTemplate(input_variables=['format_instructions', 'it_support_msg'], template='\\n             Act as an Information Technology (IT) customer support agent. For the IT support message mentioned below\\n             in triple backticks use the following format when generating the output response\\n\\n             Output format instructions:\\n             {format_instructions}\\n\\n             Customer IT support message:\\n             ```{it_support_msg}```\\n             ')\n",
              "| ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x7b67b7ffc670>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7b67b7ffdd80>, temperature=0.0, openai_api_key=SecretStr('**********'), openai_proxy='')\n",
              "| JsonOutputParser(pydantic_object=<class '__main__.ITSupportResponse'>)"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "it_support_queue = [\n",
        "    \"Não consigo sincronizar meus contatos com o telefone. Sempre recebo uma mensagem de falha.\",\n",
        "    \"Ho problemi a stampare i documenti da remoto. Il lavoro non viene inviato alla stampante di rete.\",\n",
        "    \"プリンターのトナーを交換しましたが、印刷品質が低下しています。サポートが必要です。\",\n",
        "    \"Я не могу войти в систему учета времени, появляется сообщение об ошибке. Мне нужна помощь.\",\n",
        "    \"Internet bağlantım çok yavaş ve bazen tamamen kesiliyor. Yardım eder misiniz?\",\n",
        "    \"Не могу установить обновление безопасности. Появляется код ошибки. Помогите, пожалуйста.\"\n",
        "]\n",
        "\n",
        "formatted_msgs = [{\"it_support_msg\": msg, \"format_instructions\": parser.get_format_instructions()}\n",
        "                    for msg in it_support_queue]\n",
        "formatted_msgs[0]"
      ],
      "metadata": {
        "id": "c3dlBUHh7682",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "594a060c-3874-4361-d589-d5780d646866"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'it_support_msg': 'Não consigo sincronizar meus contatos com o telefone. Sempre recebo uma mensagem de falha.',\n",
              " 'format_instructions': 'The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"properties\": {\"orig_msg\": {\"title\": \"Orig Msg\", \"description\": \"The original customer IT support query message\", \"type\": \"string\"}, \"orig_lang\": {\"title\": \"Orig Lang\", \"description\": \"Detected language of the customer message e.g. Spanish\", \"type\": \"string\"}, \"category\": {\"title\": \"Category\", \"description\": \"1-2 word describing the category of the problem\", \"type\": \"string\"}, \"trans_msg\": {\"title\": \"Trans Msg\", \"description\": \"Translated customer IT support query message in English\", \"type\": \"string\"}, \"response\": {\"title\": \"Response\", \"description\": \"Response to the customer in their original language - orig_lang\", \"type\": \"string\"}, \"trans_response\": {\"title\": \"Trans Response\", \"description\": \"Response to the customer in English\", \"type\": \"string\"}}, \"required\": [\"orig_msg\", \"orig_lang\", \"category\", \"trans_msg\", \"response\", \"trans_response\"]}\\n```'}"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "responses = llm_chain.map().invoke(formatted_msgs)"
      ],
      "metadata": {
        "id": "CnxspdUb8rSd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "responses[0], type(responses[0])"
      ],
      "metadata": {
        "id": "bLhLZnQi8xqq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa67646d-c2c2-42f0-c315-0ea536b9e95f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'orig_msg': 'Não consigo sincronizar meus contatos com o telefone. Sempre recebo uma mensagem de falha.',\n",
              "  'orig_lang': 'Portuguese',\n",
              "  'category': 'Sync Issue',\n",
              "  'trans_msg': \"I can't sync my contacts with the phone. I always get a failure message.\",\n",
              "  'response': 'Por favor, verifique se a conexão com a internet está funcionando corretamente e tente sincronizar novamente. Se o problema persistir, entre em contato com nosso suporte técnico para obter assistência adicional.',\n",
              "  'trans_response': 'Please check if the internet connection is working properly and try to sync again. If the issue persists, please contact our technical support for further assistance.'},\n",
              " dict)"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame(responses)\n",
        "df"
      ],
      "metadata": {
        "id": "aJJMXDsV82Pd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "outputId": "95926636-c2b9-42cf-d174-629739f4594d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            orig_msg   orig_lang  \\\n",
              "0  Não consigo sincronizar meus contatos com o te...  Portuguese   \n",
              "1  Ho problemi a stampare i documenti da remoto. ...     Italian   \n",
              "2          プリンターのトナーを交換しましたが、印刷品質が低下しています。サポートが必要です。    Japanese   \n",
              "3  Я не могу войти в систему учета времени, появл...     Russian   \n",
              "4  Internet bağlantım çok yavaş ve bazen tamamen ...     Turkish   \n",
              "5  Не могу установить обновление безопасности. По...     Russian   \n",
              "\n",
              "                category                                          trans_msg  \\\n",
              "0             Sync Issue  I can't sync my contacts with the phone. I alw...   \n",
              "1               Printing  I am having trouble printing documents remotel...   \n",
              "2                Printer  I replaced the printer toner but the print qua...   \n",
              "3            Login Issue  I can't log into the time tracking system, an ...   \n",
              "4  Internet Connectivity  My internet connection is very slow and someti...   \n",
              "5           Installation  Unable to install security update. Error code ...   \n",
              "\n",
              "                                            response  \\\n",
              "0  Por favor, verifique se a conexão com a intern...   \n",
              "1  Grazie per averci contattato. Per risolvere il...   \n",
              "2  トナーを正しく交換した場合、印刷品質が低下する可能性があります。まずはプリンターを再起動して...   \n",
              "3  Пожалуйста, попробуйте сбросить пароль и попро...   \n",
              "4  Evet, tabii ki yardımcı olabiliriz. İnternet b...   \n",
              "5  Извините за возникшие проблемы. Давайте попроб...   \n",
              "\n",
              "                                      trans_response  \n",
              "0  Please check if the internet connection is wor...  \n",
              "1  Thank you for reaching out to us. To resolve t...  \n",
              "2  If you correctly replaced the toner, there mig...  \n",
              "3  Please try resetting your password and attempt...  \n",
              "4  Yes, of course we can help. We will assist you...  \n",
              "5  Apologies for the inconvenience. Let's try to ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-67da7127-4301-440b-aa42-41b35280c688\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>orig_msg</th>\n",
              "      <th>orig_lang</th>\n",
              "      <th>category</th>\n",
              "      <th>trans_msg</th>\n",
              "      <th>response</th>\n",
              "      <th>trans_response</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Não consigo sincronizar meus contatos com o te...</td>\n",
              "      <td>Portuguese</td>\n",
              "      <td>Sync Issue</td>\n",
              "      <td>I can't sync my contacts with the phone. I alw...</td>\n",
              "      <td>Por favor, verifique se a conexão com a intern...</td>\n",
              "      <td>Please check if the internet connection is wor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ho problemi a stampare i documenti da remoto. ...</td>\n",
              "      <td>Italian</td>\n",
              "      <td>Printing</td>\n",
              "      <td>I am having trouble printing documents remotel...</td>\n",
              "      <td>Grazie per averci contattato. Per risolvere il...</td>\n",
              "      <td>Thank you for reaching out to us. To resolve t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>プリンターのトナーを交換しましたが、印刷品質が低下しています。サポートが必要です。</td>\n",
              "      <td>Japanese</td>\n",
              "      <td>Printer</td>\n",
              "      <td>I replaced the printer toner but the print qua...</td>\n",
              "      <td>トナーを正しく交換した場合、印刷品質が低下する可能性があります。まずはプリンターを再起動して...</td>\n",
              "      <td>If you correctly replaced the toner, there mig...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Я не могу войти в систему учета времени, появл...</td>\n",
              "      <td>Russian</td>\n",
              "      <td>Login Issue</td>\n",
              "      <td>I can't log into the time tracking system, an ...</td>\n",
              "      <td>Пожалуйста, попробуйте сбросить пароль и попро...</td>\n",
              "      <td>Please try resetting your password and attempt...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Internet bağlantım çok yavaş ve bazen tamamen ...</td>\n",
              "      <td>Turkish</td>\n",
              "      <td>Internet Connectivity</td>\n",
              "      <td>My internet connection is very slow and someti...</td>\n",
              "      <td>Evet, tabii ki yardımcı olabiliriz. İnternet b...</td>\n",
              "      <td>Yes, of course we can help. We will assist you...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Не могу установить обновление безопасности. По...</td>\n",
              "      <td>Russian</td>\n",
              "      <td>Installation</td>\n",
              "      <td>Unable to install security update. Error code ...</td>\n",
              "      <td>Извините за возникшие проблемы. Давайте попроб...</td>\n",
              "      <td>Apologies for the inconvenience. Let's try to ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-67da7127-4301-440b-aa42-41b35280c688')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-67da7127-4301-440b-aa42-41b35280c688 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-67da7127-4301-440b-aa42-41b35280c688');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-31b99ac2-cd47-4977-b127-b2106906721e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-31b99ac2-cd47-4977-b127-b2106906721e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-31b99ac2-cd47-4977-b127-b2106906721e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_b77ae625-b1fd-4074-8f6e-019c281ef691\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_b77ae625-b1fd-4074-8f6e-019c281ef691 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": \"orig_msg\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"N\\u00e3o consigo sincronizar meus contatos com o telefone. Sempre recebo uma mensagem de falha.\",\n          \"Ho problemi a stampare i documenti da remoto. Il lavoro non viene inviato alla stampante di rete.\",\n          \"\\u041d\\u0435 \\u043c\\u043e\\u0433\\u0443 \\u0443\\u0441\\u0442\\u0430\\u043d\\u043e\\u0432\\u0438\\u0442\\u044c \\u043e\\u0431\\u043d\\u043e\\u0432\\u043b\\u0435\\u043d\\u0438\\u0435 \\u0431\\u0435\\u0437\\u043e\\u043f\\u0430\\u0441\\u043d\\u043e\\u0441\\u0442\\u0438. \\u041f\\u043e\\u044f\\u0432\\u043b\\u044f\\u0435\\u0442\\u0441\\u044f \\u043a\\u043e\\u0434 \\u043e\\u0448\\u0438\\u0431\\u043a\\u0438. \\u041f\\u043e\\u043c\\u043e\\u0433\\u0438\\u0442\\u0435, \\u043f\\u043e\\u0436\\u0430\\u043b\\u0443\\u0439\\u0441\\u0442\\u0430.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"orig_lang\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Italian\",\n          \"Turkish\",\n          \"Japanese\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"category\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"Sync Issue\",\n          \"Printing\",\n          \"Installation\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"trans_msg\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"I can't sync my contacts with the phone. I always get a failure message.\",\n          \"I am having trouble printing documents remotely. The job is not being sent to the network printer.\",\n          \"Unable to install security update. Error code is appearing. Please help.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"response\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"Por favor, verifique se a conex\\u00e3o com a internet est\\u00e1 funcionando corretamente e tente sincronizar novamente. Se o problema persistir, entre em contato com nosso suporte t\\u00e9cnico para obter assist\\u00eancia adicional.\",\n          \"Grazie per averci contattato. Per risolvere il problema, ti consigliamo di controllare la connessione di rete e assicurarti che la stampante sia correttamente configurata. Se il problema persiste, ti preghiamo di contattarci nuovamente per ulteriore assistenza.\",\n          \"\\u0418\\u0437\\u0432\\u0438\\u043d\\u0438\\u0442\\u0435 \\u0437\\u0430 \\u0432\\u043e\\u0437\\u043d\\u0438\\u043a\\u0448\\u0438\\u0435 \\u043f\\u0440\\u043e\\u0431\\u043b\\u0435\\u043c\\u044b. \\u0414\\u0430\\u0432\\u0430\\u0439\\u0442\\u0435 \\u043f\\u043e\\u043f\\u0440\\u043e\\u0431\\u0443\\u0435\\u043c \\u0440\\u0435\\u0448\\u0438\\u0442\\u044c \\u044d\\u0442\\u0443 \\u043f\\u0440\\u043e\\u0431\\u043b\\u0435\\u043c\\u0443 \\u0432\\u043c\\u0435\\u0441\\u0442\\u0435. \\u041f\\u043e\\u0436\\u0430\\u043b\\u0443\\u0439\\u0441\\u0442\\u0430, \\u0443\\u0442\\u043e\\u0447\\u043d\\u0438\\u0442\\u0435 \\u043a\\u043e\\u0434 \\u043e\\u0448\\u0438\\u0431\\u043a\\u0438, \\u0447\\u0442\\u043e\\u0431\\u044b \\u043c\\u044b \\u043c\\u043e\\u0433\\u043b\\u0438 \\u043f\\u0440\\u0435\\u0434\\u043e\\u0441\\u0442\\u0430\\u0432\\u0438\\u0442\\u044c \\u0431\\u043e\\u043b\\u0435\\u0435 \\u0442\\u043e\\u0447\\u043d\\u043e\\u0435 \\u0440\\u0435\\u0448\\u0435\\u043d\\u0438\\u0435.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"trans_response\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"Please check if the internet connection is working properly and try to sync again. If the issue persists, please contact our technical support for further assistance.\",\n          \"Thank you for reaching out to us. To resolve the issue, we recommend checking the network connection and ensuring that the printer is properly configured. If the problem persists, please contact us again for further assistance.\",\n          \"Apologies for the inconvenience. Let's try to solve this issue together. Please provide the error code so we can offer a more accurate solution.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Caching in LangChain\n",
        "\n",
        "LangChain includes an optional caching layer for language model APIs (LLMs). This caching feature is beneficial for two main reasons:\n",
        "\n",
        "1. **Cost Efficiency:** By caching responses, you reduce the number of API calls made to LLM providers, especially helpful if you are frequently requesting the same completions. This can significantly lower costs.\n",
        "\n",
        "2. **Performance Improvement:** Caching can enhance your application's speed by decreasing the need for repeated API calls to the LLM provider, making interactions quicker and more efficient.\n"
      ],
      "metadata": {
        "id": "SIxhz_-rIc7A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### InMemoryCache"
      ],
      "metadata": {
        "id": "RTXKlly1I7r5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# integrations with other caching tools:\n",
        "# https://api.python.langchain.com/en/latest/community_api_reference.html#module-langchain_community.cache\n",
        "from langchain.cache import InMemoryCache\n",
        "from langchain.globals import set_llm_cache\n",
        "\n",
        "set_llm_cache(InMemoryCache())\n",
        "\n",
        "# The first time, it is not yet in cache, so it should take longer\n",
        "\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "prompt = \"\"\"Explain to me what is mortgage\"\"\"\n",
        "\n",
        "chat_template = ChatPromptTemplate.from_template(prompt)\n",
        "\n",
        "chatgpt.invoke(chat_template.format())"
      ],
      "metadata": {
        "id": "25pMMHnJDds6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e17bed73-5519-4955-aa1b-ca784dbe93e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 282 ms, sys: 39.9 ms, total: 322 ms\n",
            "Wall time: 2.18 s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='A mortgage is a type of loan that is used to purchase a home or other real estate property. The borrower (homebuyer) agrees to pay back the loan amount, plus interest, over a specified period of time. The property itself serves as collateral for the loan, meaning that if the borrower fails to make payments, the lender (usually a bank or financial institution) has the right to take possession of the property.', response_metadata={'token_usage': {'completion_tokens': 84, 'prompt_tokens': 15, 'total_tokens': 99}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-b43e7c33-99c9-40e6-aed4-7ff5befc4ab7-0')"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# The second time it is, so it goes faster\n",
        "chatgpt.invoke(chat_template.format())"
      ],
      "metadata": {
        "id": "fmBh0BeGFBOd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da6ed83a-e337-4665-9cb9-8d0ca22019cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2.18 ms, sys: 6 µs, total: 2.19 ms\n",
            "Wall time: 2.13 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='A mortgage is a type of loan that is used to purchase a home or other real estate property. The borrower (homebuyer) agrees to pay back the loan amount, plus interest, over a specified period of time. The property itself serves as collateral for the loan, meaning that if the borrower fails to make payments, the lender (usually a bank or financial institution) has the right to take possession of the property.', response_metadata={'token_usage': {'completion_tokens': 84, 'prompt_tokens': 15, 'total_tokens': 99}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-b43e7c33-99c9-40e6-aed4-7ff5befc4ab7-0')"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### SQLite Cache"
      ],
      "metadata": {
        "id": "LOVr9IJwI-w5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm langchain.db"
      ],
      "metadata": {
        "id": "WIhu_S5FFFm8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a55d2b6-6268-42a0-9ab6-e67f92a1b762"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'langchain.db': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We can do the same thing with a SQLite cache\n",
        "from langchain.cache import SQLiteCache\n",
        "\n",
        "set_llm_cache(SQLiteCache(database_path=\"langchain.db\"))"
      ],
      "metadata": {
        "id": "J_ZoRnOQFJID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# The first time, it is not yet in cache, so it should take longer\n",
        "prompt = \"\"\"Explain to me what is fractional real estate\"\"\"\n",
        "\n",
        "chat_template = ChatPromptTemplate.from_template(prompt)\n",
        "\n",
        "chatgpt.invoke(chat_template.format())"
      ],
      "metadata": {
        "id": "tfhl1XolFR81",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f0403db-c5e9-444d-e987-51295370c753"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 52.9 ms, sys: 1.62 ms, total: 54.5 ms\n",
            "Wall time: 2.15 s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content=\"Fractional real estate is a type of investment where multiple investors come together to collectively own a share of a property. Each investor owns a fraction of the property, typically represented by shares or units, and is entitled to a portion of the property's income, appreciation, and expenses. This allows investors to own a stake in high-value properties that they may not be able to afford on their own, and also provides diversification and liquidity benefits. Fractional real estate investments are often managed by a professional company or entity that handles the day-to-day operations of the property.\", response_metadata={'token_usage': {'completion_tokens': 113, 'prompt_tokens': 17, 'total_tokens': 130}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-6bb0016f-351d-47e8-897a-1df9718f29f5-0')"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# The second time it is, so it goes faster\n",
        "chatgpt.invoke(chat_template.format())"
      ],
      "metadata": {
        "id": "VSRJCYrxFZeU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "037086f2-4ca4-4405-a760-7db4c4f1a8f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 61.3 ms, sys: 26.8 ms, total: 88.1 ms\n",
            "Wall time: 97.2 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content=\"Fractional real estate is a type of investment where multiple investors come together to collectively own a share of a property. Each investor owns a fraction of the property, typically represented by shares or units, and is entitled to a portion of the property's income, appreciation, and expenses. This allows investors to own a stake in high-value properties that they may not be able to afford on their own, and also provides diversification and liquidity benefits. Fractional real estate investments are often managed by a professional company or entity that handles the day-to-day operations of the property.\", response_metadata={'token_usage': {'completion_tokens': 113, 'prompt_tokens': 17, 'total_tokens': 130}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-6bb0016f-351d-47e8-897a-1df9718f29f5-0')"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Streaming in LLMs\n",
        "\n",
        "All language model interfaces (LLMs) in LangChain implement the `Runnable` interface, which provides default methods such as `ainvoke`, `batch`, `abatch`, `stream`, and `astream`. This setup equips all LLMs with basic streaming capabilities.\n",
        "\n",
        "### Streaming Defaults:\n",
        "\n",
        "- **Synchronous Streaming:** By default, streaming operations return an `Iterator` that yields a single value, the final result from the LLM provider.\n",
        "- **Asynchronous Streaming:** Similarly, async streaming defaults to returning an `AsyncIterator` with the final result.\n",
        "\n",
        "### Limitations:\n",
        "\n",
        "- These default implementations do not support token-by-token streaming. For such detailed streaming, the LLM provider must offer native support. However, the default setup ensures that your code expecting an iterator of tokens will function correctly within these constraints.\n"
      ],
      "metadata": {
        "id": "esVD-ghbJCDD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"Explain to me what is mortgage in detail with pros and cons\"\"\"\n",
        "\n",
        "chat_template = ChatPromptTemplate.from_template(prompt)\n",
        "\n",
        "for chunk in chatgpt.stream(chat_template.format()):\n",
        "    print(chunk.content)"
      ],
      "metadata": {
        "id": "mu7GykqNF7He",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30b91c07-00ef-4ae6-dc0a-1fa2cc2c115e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "A\n",
            " mortgage\n",
            " is\n",
            " a\n",
            " type\n",
            " of\n",
            " loan\n",
            " that\n",
            " is\n",
            " used\n",
            " to\n",
            " purchase\n",
            " a\n",
            " home\n",
            " or\n",
            " real\n",
            " estate\n",
            " property\n",
            ".\n",
            " The\n",
            " borrower\n",
            " (\n",
            "home\n",
            "buyer\n",
            ")\n",
            " agrees\n",
            " to\n",
            " pay\n",
            " back\n",
            " the\n",
            " loan\n",
            " amount\n",
            ",\n",
            " plus\n",
            " interest\n",
            ",\n",
            " over\n",
            " a\n",
            " specified\n",
            " period\n",
            " of\n",
            " time\n",
            ".\n",
            " The\n",
            " property\n",
            " itself\n",
            " serves\n",
            " as\n",
            " collateral\n",
            " for\n",
            " the\n",
            " loan\n",
            ",\n",
            " meaning\n",
            " that\n",
            " if\n",
            " the\n",
            " borrower\n",
            " fails\n",
            " to\n",
            " make\n",
            " payments\n",
            ",\n",
            " the\n",
            " lender\n",
            " (\n",
            "usually\n",
            " a\n",
            " bank\n",
            " or\n",
            " financial\n",
            " institution\n",
            ")\n",
            " has\n",
            " the\n",
            " right\n",
            " to\n",
            " fore\n",
            "close\n",
            " on\n",
            " the\n",
            " property\n",
            " and\n",
            " sell\n",
            " it\n",
            " to\n",
            " rec\n",
            "oup\n",
            " their\n",
            " losses\n",
            ".\n",
            "\n",
            "\n",
            "Pros\n",
            " of\n",
            " a\n",
            " mortgage\n",
            ":\n",
            "\n",
            "\n",
            "1\n",
            ".\n",
            " Home\n",
            "ownership\n",
            ":\n",
            " One\n",
            " of\n",
            " the\n",
            " biggest\n",
            " advantages\n",
            " of\n",
            " a\n",
            " mortgage\n",
            " is\n",
            " that\n",
            " it\n",
            " allows\n",
            " individuals\n",
            " to\n",
            " become\n",
            " homeowners\n",
            " without\n",
            " having\n",
            " to\n",
            " pay\n",
            " the\n",
            " full\n",
            " purchase\n",
            " price\n",
            " upfront\n",
            ".\n",
            " This\n",
            " can\n",
            " provide\n",
            " stability\n",
            " and\n",
            " security\n",
            " for\n",
            " the\n",
            " borrower\n",
            " and\n",
            " their\n",
            " family\n",
            ".\n",
            "\n",
            "\n",
            "2\n",
            ".\n",
            " Tax\n",
            " benefits\n",
            ":\n",
            " In\n",
            " many\n",
            " countries\n",
            ",\n",
            " homeowners\n",
            " can\n",
            " deduct\n",
            " mortgage\n",
            " interest\n",
            " payments\n",
            " from\n",
            " their\n",
            " taxable\n",
            " income\n",
            ",\n",
            " which\n",
            " can\n",
            " result\n",
            " in\n",
            " significant\n",
            " savings\n",
            ".\n",
            "\n",
            "\n",
            "3\n",
            ".\n",
            " Building\n",
            " equity\n",
            ":\n",
            " As\n",
            " the\n",
            " borrower\n",
            " makes\n",
            " mortgage\n",
            " payments\n",
            ",\n",
            " they\n",
            " are\n",
            " gradually\n",
            " building\n",
            " equity\n",
            " in\n",
            " their\n",
            " home\n",
            ".\n",
            " This\n",
            " can\n",
            " be\n",
            " a\n",
            " valuable\n",
            " asset\n",
            " that\n",
            " can\n",
            " be\n",
            " used\n",
            " for\n",
            " future\n",
            " financial\n",
            " needs\n",
            ".\n",
            "\n",
            "\n",
            "Cons\n",
            " of\n",
            " a\n",
            " mortgage\n",
            ":\n",
            "\n",
            "\n",
            "1\n",
            ".\n",
            " Debt\n",
            ":\n",
            " Taking\n",
            " on\n",
            " a\n",
            " mortgage\n",
            " means\n",
            " taking\n",
            " on\n",
            " a\n",
            " significant\n",
            " amount\n",
            " of\n",
            " debt\n",
            ",\n",
            " which\n",
            " can\n",
            " be\n",
            " a\n",
            " burden\n",
            " for\n",
            " some\n",
            " borrowers\n",
            ".\n",
            " It\n",
            " is\n",
            " important\n",
            " to\n",
            " carefully\n",
            " consider\n",
            " whether\n",
            " you\n",
            " can\n",
            " afford\n",
            " the\n",
            " monthly\n",
            " payments\n",
            " before\n",
            " taking\n",
            " out\n",
            " a\n",
            " mortgage\n",
            ".\n",
            "\n",
            "\n",
            "2\n",
            ".\n",
            " Interest\n",
            " payments\n",
            ":\n",
            " Over\n",
            " the\n",
            " life\n",
            " of\n",
            " the\n",
            " loan\n",
            ",\n",
            " borrowers\n",
            " will\n",
            " pay\n",
            " a\n",
            " significant\n",
            " amount\n",
            " of\n",
            " interest\n",
            " on\n",
            " top\n",
            " of\n",
            " the\n",
            " principal\n",
            " amount\n",
            " borrowed\n",
            ".\n",
            " This\n",
            " can\n",
            " add\n",
            " up\n",
            " to\n",
            " a\n",
            " substantial\n",
            " sum\n",
            " over\n",
            " time\n",
            ".\n",
            "\n",
            "\n",
            "3\n",
            ".\n",
            " Risk\n",
            " of\n",
            " foreclosure\n",
            ":\n",
            " If\n",
            " the\n",
            " borrower\n",
            " is\n",
            " unable\n",
            " to\n",
            " make\n",
            " their\n",
            " mortgage\n",
            " payments\n",
            ",\n",
            " they\n",
            " risk\n",
            " losing\n",
            " their\n",
            " home\n",
            " through\n",
            " foreclosure\n",
            ".\n",
            " This\n",
            " can\n",
            " have\n",
            " serious\n",
            " financial\n",
            " and\n",
            " emotional\n",
            " consequences\n",
            ".\n",
            "\n",
            "\n",
            "Overall\n",
            ",\n",
            " a\n",
            " mortgage\n",
            " can\n",
            " be\n",
            " a\n",
            " valuable\n",
            " tool\n",
            " for\n",
            " achieving\n",
            " homeowners\n",
            "hip\n",
            " and\n",
            " building\n",
            " wealth\n",
            ",\n",
            " but\n",
            " it\n",
            " is\n",
            " important\n",
            " to\n",
            " carefully\n",
            " consider\n",
            " the\n",
            " risks\n",
            " and\n",
            " benefits\n",
            " before\n",
            " taking\n",
            " on\n",
            " this\n",
            " type\n",
            " of\n",
            " debt\n",
            ".\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for chunk in chatgpt.stream(chat_template.format()):\n",
        "    print(chunk.content, end=\"\")"
      ],
      "metadata": {
        "id": "8ZgtSviWGAvv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1276499-06d5-4aaa-96ed-619ed69dfee4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A mortgage is a type of loan that is used to purchase a home or other real estate property. The borrower (homebuyer) agrees to pay back the loan amount, plus interest, over a specified period of time. The property itself serves as collateral for the loan, meaning that if the borrower fails to make their mortgage payments, the lender (usually a bank or financial institution) has the right to foreclose on the property and sell it to recoup their losses.\n",
            "\n",
            "Pros of getting a mortgage:\n",
            "1. Allows you to purchase a home without having to pay the full purchase price upfront.\n",
            "2. Can help you build equity in your home over time.\n",
            "3. Mortgage interest payments may be tax-deductible.\n",
            "4. Fixed-rate mortgages offer predictable monthly payments.\n",
            "\n",
            "Cons of getting a mortgage:\n",
            "1. You will be paying interest on the loan amount, which can add up to a significant amount over the life of the loan.\n",
            "2. If you fail to make your mortgage payments, you risk losing your home through foreclosure.\n",
            "3. Closing costs and other fees associated with getting a mortgage can be expensive.\n",
            "4. Your credit score and financial history will be taken into account when applying for a mortgage, which can make it difficult for some people to qualify.\n",
            "\n",
            "Overall, a mortgage can be a useful tool for purchasing a home, but it is important to carefully consider the terms of the loan and your ability to make the required payments before taking on this financial commitment."
          ]
        }
      ]
    }
  ]
}